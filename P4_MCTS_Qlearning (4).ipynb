{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f7712e-2a96-43ed-b99a-c7f99860de45",
   "metadata": {
    "id": "77f7712e-2a96-43ed-b99a-c7f99860de45"
   },
   "source": [
    "# P4: RL & MCTS\n",
    "\n",
    "[Instructions are the same as they have been. You know the drill by now.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a27c2a-3607-487e-9fe9-b72cef77c9ba",
   "metadata": {
    "id": "91a27c2a-3607-487e-9fe9-b72cef77c9ba"
   },
   "source": [
    "To begin, you will revisit the graph problem from the last assignment, yet this time you will solve it using Q-Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b522db4-f476-4df6-9be0-8783dbec587f",
   "metadata": {
    "id": "1b522db4-f476-4df6-9be0-8783dbec587f"
   },
   "outputs": [],
   "source": [
    "# Starter Code: Graph definition and plotting (the same as P3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def get_random_adjacency(band_size, num_nodes, edge_rate=1.0, seed=695):\n",
    "    random.seed(seed)\n",
    "    mat = np.zeros((num_nodes, num_nodes))\n",
    "    for ii in range(num_nodes):\n",
    "        mat[ii, ii] = 1.0\n",
    "        for jj in range(ii + 1, min(ii+band_size, num_nodes)):\n",
    "            val = 1.0 * (random.random() < edge_rate)\n",
    "            mat[ii, jj] = val\n",
    "            mat[jj, ii] = val\n",
    "    return mat\n",
    "\n",
    "\n",
    "def plot_adjacency_mat(mat):\n",
    "    plt.figure(dpi=150)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.imshow(mat, interpolation='none')\n",
    "\n",
    "\n",
    "class AdjacencyWorld(object):\n",
    "    def __init__(self, num_nodes, band_size=10, edge_rate=0.5, random_move_chance=0.5, seed=695):\n",
    "        self.mat = get_random_adjacency(band_size=band_size, num_nodes=num_nodes, edge_rate=edge_rate, seed=seed)\n",
    "        self.states = list(range(num_nodes))\n",
    "        self.rewards = -1 * np.ones((num_nodes))\n",
    "        self.goal = num_nodes//2\n",
    "        self.rewards[self.goal] = 10\n",
    "        self.random_move_chance = random_move_chance\n",
    "\n",
    "    def get_actions_for_state(self, state):\n",
    "        \"\"\"Get the available 'moves' from the current state.\n",
    "        return: list of indices connected to 'state'.\"\"\"\n",
    "        return np.where(self.mat[state])[0].tolist()\n",
    "\n",
    "    def get_transition_probs(self, state, action):\n",
    "        \"\"\"Get a list of the transition probabilities for a state and action.\"\"\"\n",
    "        actions = self.get_actions_for_state(state)\n",
    "        num_actions = len(actions)\n",
    "        prob_vec = np.zeros_like(self.rewards)\n",
    "        for rand_action in actions:\n",
    "            prob_vec[rand_action] = self.random_move_chance / num_actions\n",
    "\n",
    "        prob_vec[action] += (1 - self.random_move_chance)\n",
    "        return prob_vec\n",
    "\n",
    "    def get_random_state(self):\n",
    "        return random.choice(self.states)\n",
    "\n",
    "    def execute_action(self, state, action):\n",
    "        assert action in self.get_actions_for_state(state)\n",
    "        probs = self.get_transition_probs(state, action)\n",
    "        new_state = np.random.choice(self.states, p=probs)\n",
    "        return self.rewards[new_state], new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df753ea6-731a-45ce-928c-505035d261df",
   "metadata": {
    "id": "df753ea6-731a-45ce-928c-505035d261df"
   },
   "source": [
    "## P4.1: Q Learning\n",
    "\n",
    "Next, you'll be implementing Q Learning. Instructions here are a bit sparse, but I figure you probably know what you're doing by now!\n",
    "\n",
    "**TASK** Implement Q Learning (use the lecture slides as a reference).\n",
    "\n",
    "**TASK** Complete the `evaluate_policy` function using your implementation from the previous assignment (or mine). We will not grade this function, but it is necessary to complete your Q Learning evaluation code.\n",
    "\n",
    "**CODE** Include your Q Learning implementation in your writeup\n",
    "\n",
    "**PLOTS** Run the evaluation code below. Include all plots and the results (the average value for each value of the learning rate) in your writeup. You should notice the performance peaks around a learning rate of 0.02.\n",
    "\n",
    "**QUESTION** (1-3 sentences) The rate of convergence for Q learning is significantly slower than that of Value Iteration. What information does Value Iteration have access to (and indeed makes use of) that makes it converge faster?\n",
    "\n",
    "**QUESTION** (3-5 sentences) When the learning rate is very low, the performance is not particularly good. From looking at the plots of the total reward over time, what is likely the cause? How would you fix this issue (without changing the learning rate)?\n",
    "\n",
    "**QUESTION** (2-4 sentences) When the learning is too high, the performance is also not very good. Why does this happen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tHiwTu1LCcW0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "tHiwTu1LCcW0",
    "outputId": "66036a90-b5e7-407f-f8f8-c6028f96dda9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABsqElEQVR4nO3dd1hTZ/8G8DthJMgIskHBXQEHKgjaOqpSRa2Ke9et7avVautrfTttbe1UWxdarVpH3eJoi7WKq+LCvVCUOhkqG2Ulz+8PS35NASWacBK4P9eVq81znpx8zyGSm3Oe5xyZEEKAiIiIqIKSS10AERERkTEx7BAREVGFxrBDREREFRrDDhEREVVoDDtERERUoTHsEBERUYXGsENEREQVGsMOERERVWgMO0RERFShMewQkdn7+OOPIZPJpC7DbO3btw8ymQz79u2TuhQio2DYoQph4cKFkMlkCAkJkboUk1OzZk3IZDLtw9bWFsHBwfjpp5+kLq3Cefnll9GwYUOpyzArK1as0Pl8Wlpaolq1ahg+fDju3LnzTOt8+PAhPv74Y4Y30rKUugAiQ1izZg1q1qyJY8eOIT4+HnXr1pW6JJPSpEkTvP322wCAxMRELF26FMOGDUNeXh7GjBkjcXUktTZt2uDRo0ewtraWrIZPPvkEtWrVQm5uLo4cOYIVK1bg0KFDOH/+PJRKpV7revjwIWbMmAHgcQAl4pEdMnsJCQk4fPgwZs+eDVdXV6xZs6bca9BoNMjNzS339y2ratWqYciQIRgyZAimTp2KQ4cOwc7ODnPmzJG6tDIpLCxEfn6+1GWYjZycHL36y+VyKJVKyOXSfSV07twZQ4YMwejRo7F06VK88847uHbtGrZv3y5ZTVRxMOyQ2VuzZg2qVq2Krl27ok+fPjphp6CgAE5OThgxYkSx12VmZkKpVOKdd97RtuXl5eGjjz5C3bp1oVAo4O3tjf/+97/Iy8vTea1MJsOECROwZs0aNGjQAAqFAlFRUQCAb775Bi+++CKcnZ1hY2ODwMBAbNq0qdj7P3r0CBMnToSLiwvs7e3RvXt33LlzBzKZDB9//LFO3zt37mDkyJFwd3eHQqFAgwYN8OOPPz7zPnN1dYWvry+uXbum067RaDB37lw0aNAASqUS7u7uGDduHNLS0rR9pkyZAmdnZwghtG1vvvkmZDIZvv/+e21bcnIyZDIZFi1aBADIz8/Hhx9+iMDAQKhUKtja2qJ169aIjo7WqeGvv/6CTCbDN998g7lz56JOnTpQKBS4ePEiAODQoUNo3rw5lEol6tSpg8WLF5dpmydMmAA7Ozs8fPiw2LKBAwfCw8MDarUaAHDixAl06tQJLi4usLGxQa1atTBy5MgyvU9Z/Pbbb2jdujVsbW1hb2+Prl274sKFCzp9zp49i+HDh6N27dpQKpXw8PDAyJEj8eDBA51+ReOVLl68iEGDBqFq1apo1aoVgMenMF999VUcOnQIwcHBUCqVqF27drFTmCWN2Sk6JXfx4kW0a9cOVapUQbVq1fDVV18V254bN26ge/fusLW1hZubGyZPnoxdu3Y91zig1q1bA4DOZ7Qsn6G//voLrq6uAIAZM2ZoT4/989/U5cuX0adPHzg5OUGpVCIoKIihqqITRGbO19dXjBo1SgghxIEDBwQAcezYMe3ykSNHCkdHR5GXl6fzupUrVwoA4vjx40IIIdRqtejYsaOoUqWKeOutt8TixYvFhAkThKWlpejRo4fOawEIPz8/4erqKmbMmCEWLFggTp06JYQQonr16uI///mPmD9/vpg9e7YIDg4WAMTOnTt11tGvXz8BQAwdOlQsWLBA9OvXTwQEBAgA4qOPPtL2S0pKEtWrVxfe3t7ik08+EYsWLRLdu3cXAMScOXOeun9q1KghunbtqtNWUFAgPDw8hLu7u0776NGjhaWlpRgzZoyIiIgQ06ZNE7a2tqJ58+YiPz9fCCHEli1bBABx7tw57esCAgKEXC4Xffr00bZt3LhRABDnz58XQghx79494enpKaZMmSIWLVokvvrqK1G/fn1hZWWl3XdCCJGQkCAACH9/f1G7dm3xxRdfiDlz5ogbN26Is2fPChsbG+Hj4yNmzZolPv30U+Hu7i4aN24snvbrrOizsWHDBp32nJwcYWtrK8aPHy+EECI5OVlUrVpVvPDCC+Lrr78WP/zwg3jvvfeEn5/fU/d127ZtRYMGDZ7Y56effhIymUyEhYWJefPmiS+//FLUrFlTODo6ioSEBG2/b775RrRu3Vp88sknYsmSJWLSpEnCxsZGBAcHC41Go+330UcfafdXjx49xMKFC8WCBQuEEI9/9vXr1xfu7u7if//7n5g/f75o1qyZkMlk2p+LEEJER0cLACI6OlpnW7y8vIS3t7eYNGmSWLhwoWjfvr0AIH799Vdtv+zsbFG7dm1hY2Mj3n33XTF37lwRHBys/Sz/c50lWb58uc6/wyLz588XAMSiRYu0bWX5DGVnZ4tFixYJAKJnz55i1apVYtWqVeLMmTNCCCHOnz8vVCqV8Pf3F19++aWYP3++aNOmjZDJZGLLli1PrJXMF8MOmbUTJ04IAGL37t1CCCE0Go2oXr26mDRpkrbPrl27BACxY8cOndd26dJF1K5dW/t81apVQi6Xi4MHD+r0i4iIEADEn3/+qW0DIORyubhw4UKxmh4+fKjzPD8/XzRs2FC0b99e2xYbGysAiLfeekun7/Dhw4uFnVGjRglPT09x//59nb4DBgwQKpWq2Pv9W40aNUTHjh3FvXv3xL1798S5c+fE0KFDBQDtF7wQQhw8eFAAEGvWrNF5fVRUlE57SkqKACAWLlwohBAiPT1dyOVy0bdvX53wNHHiROHk5KT9Yi4sLCwWONPS0oS7u7sYOXKktq0o7Dg4OIiUlBSd/uHh4UKpVIobN25o2y5evCgsLCyeGnY0Go2oVq2a6N27t077hg0bBABx4MABIYQQW7duLfHLtyyeFnaysrKEo6OjGDNmjE57UlKSUKlUOu0l/Vx//vlnnVqF+P+wM3DgwGL9a9SoUax/SkqKUCgU4u2339a2lRZ2AIiffvpJ25aXlyc8PDx09uG3334rAIjIyEht26NHj4Svr69eYeePP/4Q9+7dE7du3RKbNm0Srq6uQqFQiFu3bmn7lvUzdO/evWL/jop06NBBNGrUSOTm5mrbNBqNePHFF0W9evWeWCuZL57GIrO2Zs0auLu7o127dgAen17q378/1q1bpz0l0b59e7i4uGD9+vXa16WlpWH37t3o37+/tm3jxo3w8/ODr68v7t+/r320b98eAIqdbmnbti38/f2L1WRjY6PzPhkZGWjdujVOnjypbS865fWf//xH57VvvvmmznMhBDZv3oxu3bpBCKFTV6dOnZCRkaGz3tL8/vvvcHV1haurKxo1aoRVq1ZhxIgR+Prrr3W2X6VS4ZVXXtF5n8DAQNjZ2Wm3v+gU2IEDBwAAf/75JywsLDB16lQkJyfj6tWrAICDBw+iVatW2inhFhYW2gGwGo0GqampKCwsRFBQUInb0Lt3b+3pCABQq9XYtWsXwsPD4ePjo2338/NDp06dnroPZDIZ+vbti19//RXZ2dna9vXr16NatWraUz+Ojo4AgJ07d6KgoOCp69XH7t27kZ6ejoEDB+rsYwsLC4SEhOh8xv75OcrNzcX9+/fRokULAChxf73++uslvqe/v7/2lBDw+OdXv359XL9+/an12tnZYciQIdrn1tbWCA4O1nltVFQUqlWrhu7du2vblEql3gPfQ0ND4erqCm9vb/Tp0we2trbYvn07qlevru2j72fo31JTU7F3717069cPWVlZ2v3/4MEDdOrUCVevXn3mGWBk2hh2yGyp1WqsW7cO7dq1Q0JCAuLj4xEfH4+QkBAkJydjz549AABLS0v07t0b27Zt04692bJlCwoKCnTCztWrV3HhwgVtKCh6vPDCCwCAlJQUnfevVatWiXXt3LkTLVq0gFKphJOTE1xdXbFo0SJkZGRo+9y4cQNyubzYOv49i+zevXtIT0/HkiVLitVVNA7p33WVJCQkBLt370ZUVBS++eYbODo6Ii0tTWf2zdWrV5GRkQE3N7di75Wdna3zPq1bt8bBgwcBPA41QUFBCAoKgpOTEw4ePIjMzEycOXNG50sWAFauXInGjRtDqVTC2dkZrq6u+OWXX3T2TWn79969e3j06BHq1atXrG/9+vWfug8AoH///nj06JF2fEZ2djZ+/fVX9O3bVxvK2rZti969e2PGjBlwcXFBjx49sHz58mLjtp5FURBs3759sX38+++/6+zj1NRUTJo0Ce7u7rCxsYGrq6t2n5RlfxX5ZzAsUrVqVZ1xWKWpXr16sesX/fu1N27cQJ06dYr103dG5IIFC7B7925s2rQJXbp0wf3796FQKIr10+cz9G/x8fEQQuCDDz4otv8/+ugjAGX790Tmh1PPyWzt3bsXiYmJWLduHdatW1ds+Zo1a9CxY0cAwIABA7B48WL89ttvCA8Px4YNG+Dr64uAgABtf41Gg0aNGmH27Nklvp+3t7fO83/+5V3k4MGD6N69O9q0aYOFCxfC09MTVlZWWL58OdauXav3Nmo0GgDAkCFDMGzYsBL7NG7c+KnrcXFxQWhoKACgU6dO8PX1xauvvorvvvsOU6ZM0b6Xm5tbqbPZ/nmUpVWrVvjhhx9w/fp1HDx4EK1bt4ZMJkOrVq1w8OBBeHl5QaPR6ISd1atXY/jw4QgPD8fUqVPh5uYGCwsLzJo1q9hAaaDk/fu8WrRogZo1a2LDhg0YNGgQduzYgUePHumEXplMhk2bNuHIkSPYsWMHdu3ahZEjR+Lbb7/FkSNHYGdn98zvX/TzXLVqFTw8PIott7T8/1/J/fr1w+HDhzF16lQ0adIEdnZ20Gg0CAsL067nn0rbXxYWFiW2i38MMC/N87xWX8HBwQgKCgIAhIeHo1WrVhg0aBDi4uK0+1zfz9C/Fe23d955p9SjgbxsRcXEsENma82aNXBzc8OCBQuKLduyZQu2bt2KiIgI2NjYoE2bNvD09MT69evRqlUr7N27F++9957Oa+rUqYMzZ86gQ4cOz3w13s2bN0OpVGLXrl06f5UuX75cp1+NGjWg0WiQkJCgc6QiPj5ep5+rqyvs7e2hVqu1YcUQunbtirZt2+Lzzz/HuHHjYGtrizp16uCPP/7ASy+99NSgURRidu/ejePHj+Pdd98F8Ph6LYsWLYKXlxdsbW0RGBiofc2mTZtQu3ZtbNmyRWf/Fv1F/TSurq6wsbHRHh35p7i4uDKtA3gcIr777jtkZmZi/fr1qFmzpvb00D+1aNECLVq0wGeffYa1a9di8ODBWLduHUaPHl3m9/q3OnXqAADc3Nye+PNMS0vDnj17MGPGDHz44Yfa9pK2XWo1atTAxYsXIYTQ+bn++7Osj6IA065dO8yfP1/7+SrrZ6i0f7+1a9cGAFhZWRn03xOZPp7GIrP06NEjbNmyBa+++ir69OlT7DFhwgRkZWVpT1fI5XL06dMHO3bswKpVq1BYWKjz1zzw+Evwzp07+OGHH0p8v7Jcu8TCwgIymUw7Xgh4PBU2MjJSp1/RX5ULFy7UaZ83b16x9fXu3RubN2/G+fPni73fvXv3nlpTaaZNm4YHDx5ot7dfv35Qq9X49NNPi/UtLCxEenq69nmtWrVQrVo1zJkzBwUFBXjppZcAPA5B165dw6ZNm9CiRQudIxVFRwn+eVTg6NGjiImJKVO9FhYW6NSpEyIjI3Hz5k1t+6VLl7Br164yb3f//v2Rl5eHlStXIioqCv369dNZnpaWVuzIRZMmTQDguU9lderUCQ4ODvj8889LHA9U9PMsaV8BwNy5c5/r/Y2hU6dOuHPnjs7U7dzc3BL/Henj5ZdfRnBwMObOnau9hlVZP0NVqlQBAJ3PLPA4ZL788stYvHgxEhMTi73n8/x7ItPGIztklrZv346srCydQZH/1KJFC+0FBotCTf/+/TFv3jx89NFHaNSoEfz8/HReM3ToUGzYsAGvv/46oqOj8dJLL0GtVuPy5cvYsGEDdu3apT3MXpquXbti9uzZCAsLw6BBg5CSkoIFCxagbt26OHv2rLZfYGAgevfujblz5+LBgwdo0aIF9u/fjytXrgDQ/cv0iy++QHR0NEJCQjBmzBj4+/sjNTUVJ0+exB9//IHU1NRn2oedO3dGw4YNMXv2bIwfPx5t27bFuHHjMGvWLJw+fRodO3aElZUVrl69io0bN+K7775Dnz59tK9v3bo11q1bh0aNGqFq1aoAgGbNmsHW1hZXrlzBoEGDdN7v1VdfxZYtW9CzZ0907doVCQkJiIiIgL+/v86A4SeZMWMGoqKi0Lp1a/znP/9BYWEh5s2bhwYNGujs3ydp1qwZ6tati/feew95eXnFQu/KlSuxcOFC9OzZE3Xq1EFWVhZ++OEHODg4oEuXLk9d/7179zBz5sxi7bVq1cLgwYOxaNEiDB06FM2aNcOAAQPg6uqKmzdv4pdffsFLL72E+fPnw8HBAW3atMFXX32FgoICVKtWDb///jsSEhLKtI3lady4cZg/fz4GDhyISZMmwdPTE2vWrNFe9fh57lk2depU9O3bFytWrMDrr79e5s+QjY0N/P39sX79erzwwgtwcnJCw4YN0bBhQyxYsACtWrVCo0aNMGbMGNSuXRvJycmIiYnB7du3cebMmefeJ2SCpJoGRvQ8unXrJpRKpcjJySm1z/Dhw4WVlZV2yrZGoxHe3t4CgJg5c2aJr8nPzxdffvmlaNCggVAoFKJq1aoiMDBQzJgxQ2RkZGj74V/Ttv9p2bJlol69ekKhUAhfX1+xfPly7fTgf8rJyRHjx48XTk5Ows7OToSHh4u4uDgBQHzxxRc6fZOTk8X48eOFt7e3sLKyEh4eHqJDhw5iyZIlT91XJV1np8iKFSsEALF8+XJt25IlS0RgYKCwsbER9vb2olGjRuK///2vuHv3rs5rFyxYIACIN954Q6c9NDRUABB79uzRaddoNOLzzz8XNWrUEAqFQjRt2lTs3LlTDBs2TNSoUUPbr2jq+ddff11izfv37xeBgYHC2tpa1K5dW0RERJS4f5/kvffeEwBE3bp1iy07efKkGDhwoPDx8REKhUK4ubmJV199VZw4ceKp6y2arl3So0OHDtp+0dHRolOnTkKlUgmlUinq1Kkjhg8frvMet2/fFj179hSOjo5CpVKJvn37irt37xabUl207ffu3StWT2k/+7Zt24q2bdvq1IMSpp6XNI3+3z8vIYS4fv266Nq1q7CxsRGurq7i7bffFps3bxYAxJEjR564z0q7zo4Qj699VadOHVGnTh1RWFhY5s+QEEIcPnxY+zn59z67du2aeO2114SHh4ewsrIS1apVE6+++qrYtGnTE2sl8yUTwggjzYjomZw+fRpNmzbF6tWrMXjwYKnLIXpmc+fOxeTJk3H79m1Uq1ZN6nKokuOYHSKJPHr0qFjb3LlzIZfL0aZNGwkqIno2//4s5+bmYvHixahXrx6DDpkEjtkhkshXX32F2NhYtGvXDpaWlvjtt9/w22+/YezYscWmuROZsl69esHHxwdNmjRBRkYGVq9ejcuXL0tyU16ikvA0FpFEdu/ejRkzZuDixYvIzs6Gj48Phg4divfee09nFhORqZs7dy6WLl2Kv/76C2q1Gv7+/vjvf/9bbPA3kVQYdoiIiKhC45gdIiIiqtAYdoiIiKhC48AAPL5fyt27d2Fvb/9cF8AiIiKi8iOEQFZWFry8vCCXl378hmEHwN27dzn7hYiIyEzdunUL1atXL3U5ww4Ae3t7AI93loODg8TVEBERUVlkZmbC29tb+z1eGoYd/P+9WxwcHBh2iIiIzMzThqBwgDIRERFVaAw7REREVKEx7BAREVGFxrBDREREFRrDDhEREVVoDDtERERUoTHsEBERUYXGsENEREQVGsMOERERVWi8gjIREREZhVojcCwhFSlZuXCzVyK4lhMs5OV/w22GHSIiIjK4qPOJmLHjIhIzcrVtniolPurmj7CGnuVai6SnsWbNmoXmzZvD3t4ebm5uCA8PR1xcnE6f3NxcjB8/Hs7OzrCzs0Pv3r2RnJys0+fmzZvo2rUrqlSpAjc3N0ydOhWFhYXluSlERET0t6jziXhj9UmdoAMASRm5eGP1SUSdTyzXeiQNO/v378f48eNx5MgR7N69GwUFBejYsSNycnK0fSZPnowdO3Zg48aN2L9/P+7evYtevXppl6vVanTt2hX5+fk4fPgwVq5ciRUrVuDDDz+UYpOIiIgqNbVGYMaOixAlLCtqm7HjItSaknoYh0wIUX7v9hT37t2Dm5sb9u/fjzZt2iAjIwOurq5Yu3Yt+vTpAwC4fPky/Pz8EBMTgxYtWuC3337Dq6++irt378Ld3R0AEBERgWnTpuHevXuwtrZ+6vtmZmZCpVIhIyODdz0nIiJ6DjHXHmDgD0ee2u/nMS3Qso7zc71XWb+/TWo2VkZGBgDAyckJABAbG4uCggKEhoZq+/j6+sLHxwcxMTEAgJiYGDRq1EgbdACgU6dOyMzMxIULF0p8n7y8PGRmZuo8iIiI6PmlZOU+vZMe/QzBZMKORqPBW2+9hZdeegkNGzYEACQlJcHa2hqOjo46fd3d3ZGUlKTt88+gU7S8aFlJZs2aBZVKpX14e3sbeGuIiIgqJzd7pUH7GYLJhJ3x48fj/PnzWLdundHfa/r06cjIyNA+bt26ZfT3JCIiqgy8HJVPnF4uw+NZWcG1nMqtJpOYej5hwgTs3LkTBw4cQPXq1bXtHh4eyM/PR3p6us7RneTkZHh4eGj7HDt2TGd9RbO1ivr8m0KhgEKhMPBWEBERVW4J93Mw+IcjpQ4+LopAH3XzL9fr7Uh6ZEcIgQkTJmDr1q3Yu3cvatWqpbM8MDAQVlZW2LNnj7YtLi4ON2/eRMuWLQEALVu2xLlz55CSkqLts3v3bjg4OMDf3798NoSIiKiSi0vKQt+IGNzNyEVtV1vM6tUQnirdU1UeKiUWDWlW7tfZkXQ21n/+8x+sXbsW27ZtQ/369bXtKpUKNjY2AIA33ngDv/76K1asWAEHBwe8+eabAIDDhw8DeDz1vEmTJvDy8sJXX32FpKQkDB06FKNHj8bnn39epjo4G4uIiOjZnb+TgaHLjiLtYQF8PeyxalQIXO0VRr+Cclm/vyUNOzJZyRu8fPlyDB8+HMDjiwq+/fbb+Pnnn5GXl4dOnTph4cKFOqeobty4gTfeeAP79u2Dra0thg0bhi+++AKWlmU7S8ewQ0RE9Gxib6Ri+I/HkZVXiIDqKqwcGQzHKk+/7IshmEXYMRUMO0RERPo7HH8fo386gYf5ajSvWRU/Dm8Oe6VVub1/Wb+/TWKAMhEREZmXvZeT8frqk8gv1KB1PRcsHhqIKtamGStMsyoiIiIyWb+eS8SkdadQoBYI9XPH/EFNobSykLqsUjHsEBERUZltjr2NqZvOQCOAVxt7Yk7/JrCyMJnL9pWIYYeIiIjKZPWRG3g/8jwAoG9gdXzRu3G5Xi/nWTHsEBER0VMtPXgdM3+5BAAY1rIGPurWAHIzCDoAww4RERE9gRAC3++Jx5w/rgAAXm9bB9PC6pd6+RhTxLBDREREJRJC4Iuoy1i8/zoA4O1XXsCE9nXNKugADDtERERUAo1G4OMdF/BTzA0AwPtd/TC6dW2Jq3o2DDtERESkQ60RmLb5LDbF3oZMBnwW3giDQnykLuuZMewQERGRVoFag8nrT2Pn2UTIZcC3/QLQs2l1qct6Lgw7REREBADILVBjwtqT+ONSCqwsZPh+QFN0blS+dyg3BoYdIiIiwsP8QoxbFYuDV+/D2lKOxUMC0c7XTeqyDIJhh4iIqJLLyi3AyBXHcfyvNFSxtsDS14LwYl0XqcsyGIYdIiKiSiz9YT5e+/EYzt7OgL3SEitGNEdgDSepyzIohh0iIqJK6l5WHoYuO4rLSVmoWsUKq0aFoGE1ldRlGRzDDhERUSWUmPEIg384iuv3c+Bqr8Ca0SF4wd1e6rKMgmGHiIiokrn54CEGLT2C22mPUM3RBmtGh6Cmi63UZRkNww4REVElEp+SjcFLjyA5Mw81natg9egQVK9aReqyjIphh4iIqJK4eDcTQ5cdxYOcfNRzs8Oa0SFwc1BKXZbRMewQERFVAqdvpeO1ZUeRmVuIBl4OWDUqBE621lKXVS4YdoiIiCq4o9cfYNTKE8jOK0QzH0csHxEMlY2V1GWVG4YdIiKiCuzAlXsYu+oEcgs0aFnbGUuHBcFWUbm+/ivX1hIREVUiv19IwoS1p5Cv1qBdfVcsGhIIpZWF1GWVO4YdIiKiCmjb6TuYsuEM1BqBzg098N2AprC2lEtdliQYdoiIiCqYDcdvYdqWsxAC6Nm0Gr7u0xiWFpUz6AAMO0RERBXKij8T8PGOiwCAQSE+mNmjIeRymcRVSYthh4iIqIJYuC8eX0XFAQBGtaqF97v6QSar3EEHYNghIiIye0IIfPv7FcyPjgcATGxfF5NfeYFB528MO0RERGZMCIFPd17Cj38mAACmhfnijZfrSFyVaWHYISIiMlNqjcD7kefw87FbAIAZ3Rtg2Is1pS3KBDHsEBERmaFCtQbvbDyDyNN3IZcBX/RujH5B3lKXZZIYdoiIiMxMfqEGE38+hagLSbCUyzCnfxN0C/CSuiyTJemk+wMHDqBbt27w8vKCTCZDZGSkzvLk5GQMHz4cXl5eqFKlCsLCwnD16lWdPrm5uRg/fjycnZ1hZ2eH3r17Izk5uRy3goiIqPzkFqgxdtUJRF1IgrWFHIuGBDLoPIWkYScnJwcBAQFYsGBBsWVCCISHh+P69evYtm0bTp06hRo1aiA0NBQ5OTnafpMnT8aOHTuwceNG7N+/H3fv3kWvXr3KczOIiIjKRXZeIYYvP4Z9cfegtJJj6bAgvOLvLnVZJk8mhBBSFwEAMpkMW7duRXh4OADgypUrqF+/Ps6fP48GDRoAADQaDTw8PPD5559j9OjRyMjIgKurK9auXYs+ffoAAC5fvgw/Pz/ExMSgRYsWZXrvzMxMqFQqZGRkwMHBwSjbR0RE9DwyHhVg+PJjOHUzHXYKS/w4vDmCazlJXZakyvr9bbLXjs7LywMAKJVKbZtcLodCocChQ4cAALGxsSgoKEBoaKi2j6+vL3x8fBATE/PEdWdmZuo8iIiITNWD7DwMXHIEp26mQ2VjhdWjQyp90NGHyYadotAyffp0pKWlIT8/H19++SVu376NxMREAEBSUhKsra3h6Oio81p3d3ckJSWVuu5Zs2ZBpVJpH97eHL1ORESmKTkzFwOWHMHFxEy42Flj3dgWaOLtKHVZZsVkw46VlRW2bNmCK1euwMnJCVWqVEF0dDQ6d+4Mufz5yp4+fToyMjK0j1u3bhmoaiIiIsO5nfYQ/RbH4GpKNjwclFg3tiX8PDncQl8mPfU8MDAQp0+fRkZGBvLz8+Hq6oqQkBAEBQUBADw8PJCfn4/09HSdozvJycnw8PAodb0KhQIKhcLY5RMRET2zhPs5GPzDEdzNyIW3kw3Wjm4Bb6cqUpdllkz2yM4/qVQquLq64urVqzhx4gR69OgB4HEYsrKywp49e7R94+LicPPmTbRs2VKqcomIiJ5LXFIW+kbE4G5GLmq72mLDuJYMOs9B0iM72dnZiI+P1z5PSEjA6dOn4eTkBB8fH2zcuBGurq7w8fHBuXPnMGnSJISHh6Njx44AHoegUaNGYcqUKXBycoKDgwPefPNNtGzZsswzsYiIiEzJudsZeO3Ho0h7WABfD3usGhUCV3uejXgekoadEydOoF27dtrnU6ZMAQAMGzYMK1asQGJiIqZMmYLk5GR4enritddewwcffKCzjjlz5kAul6N3797Iy8tDp06dsHDhwnLdDiIiIkM48VcqRiw/jqy8QgRUV2HlyGA4VrGWuiyzZzLX2ZESr7NDRERSOxx/H6NWnsCjAjWCazph2fAg2CutpC7LpJX1+9ukBygTERFVBnsvJ+P11SeRX6hB63ouWDI0CDbWFlKXVWEw7BAREUno13OJmLTuFArUAqF+7lgwuCkUlgw6hsSwQ0REJJHNsbcxddMZaATwamNPzOnfBFYWZjFR2qww7BAREUlg9ZEbeD/yPACgb2B1fNG7MSzkMomrqpgYdoiIiMrZ0oPXMfOXSwCAYS1r4KNuDSBn0DEahh0iIqJyIoTA93viMeePKwCA19vWwbSw+pDJGHSMiWGHiIioHAgh8EXUZSzefx0A8PYrL2BC+7oMOuWAYYeIiMjINBqBj3dcwE8xNwAA73f1w+jWtSWuqvJg2CEiIjIitUZg2uaz2BR7GzIZ8Fl4IwwK8ZG6rEqFYYeIiMhICtQavLX+NH45mwi5DPi2XwB6Nq0udVmVDsMOERGREeQWqDFh7Un8cSkFVhYyfD+gKTo38pS6rEqJYYeIiMjAHuYXYtyqWBy8eh8KSzkihgSina+b1GVVWgw7REREBpSVW4CRK47j+F9pqGJtgaXDgvBiHRepy6rUGHaIiIgMJP1hPl778RjO3s6AvdISK0Y0R2ANJ6nLqvQYdoiIiAzgXlYehi47istJWahaxQqrRoWgYTWV1GURGHaIiIieW2LGIwz+4Siu38+Bq70Ca0aH4AV3e6nLor8x7BARET2Hmw8eYtDSI7id9gjVHG2wZnQIarrYSl0W/QPDDhER0TOKT8nG4KVHkJyZh5rOVbB6dAiqV60idVn0Lww7REREz+Di3UwMXXYUD3LyUc/NDmtGh8DNQSl1WVQChh0iIiI9nbqZhmE/HkNmbiEaeDlg1agQONlaS10WlYJhh4iISA9Hrz/AyBXHkZOvRjMfRywfEQyVjZXUZdETMOwQERGV0f4r9zBu1QnkFmjQsrYzlg4Lgq2CX6Wmjj8hIiKiMvj9QhImrD2FfLUG7eq7YtGQQCitLKQui8qAYYeIiOgptp2+gykbzkCtEejc0APfDWgKa0u51GVRGTHsEBERPcGG47cwbctZCAH0aloNX/VpDEsLBh1zwrBDRERUihV/JuDjHRcBAINCfDCzR0PI5TKJqyJ9MewQERGVYOG+eHwVFQcAGNWqFt7v6geZjEHHHDHsEBER/YMQAt/+fgXzo+MBABPb18XkV15g0DFjDDtERER/E0Lg052X8OOfCQCAaWG+eOPlOhJXRc+LYYeIiAiAWiPwfuQ5/HzsFgBgRvcGGPZiTWmLIoNg2CEiokqvUK3BOxvPIPL0XchlwBe9G6NfkLfUZZGBMOwQEVGllleoxsSfT2HXhWRYymWY078JugV4SV0WGRDDDhERVVq5BWqMWxWL/VfuwdpCjgWDm+EVf3epyyIDk/SqSAcOHEC3bt3g5eUFmUyGyMhIneXZ2dmYMGECqlevDhsbG/j7+yMiIkKnT25uLsaPHw9nZ2fY2dmhd+/eSE5OLsetICIic5SdV4jhy49h/5V7UFrJsWx4EINOBSVp2MnJyUFAQAAWLFhQ4vIpU6YgKioKq1evxqVLl/DWW29hwoQJ2L59u7bP5MmTsWPHDmzcuBH79+/H3bt30atXr/LaBCIiMkMZjwowdNlRHLmeCjuFJX4aGYLW9VylLouMRCaEEFIXAQAymQxbt25FeHi4tq1hw4bo378/PvjgA21bYGAgOnfujJkzZyIjIwOurq5Yu3Yt+vTpAwC4fPky/Pz8EBMTgxYtWpTpvTMzM6FSqZCRkQEHBweDbhcREZmWB9l5GLrsGC4mZkJlY4WfRgYjwNtR6rLoGZT1+9ukb+7x4osvYvv27bhz5w6EEIiOjsaVK1fQsWNHAEBsbCwKCgoQGhqqfY2vry98fHwQExNT6nrz8vKQmZmp8yAiooovOTMXA5YcwcXETLjYWWPd2BYMOpWASYedefPmwd/fH9WrV4e1tTXCwsKwYMECtGnTBgCQlJQEa2trODo66rzO3d0dSUlJpa531qxZUKlU2oe3N6cXEhFVdLfTHqLf4hhcTcmGh4MS68a2hJ8nj+ZXBiYfdo4cOYLt27cjNjYW3377LcaPH48//vjjudY7ffp0ZGRkaB+3bt0yUMVERGSKEu7noF9EDG48eAhvJxtsfL0l6rrZSV0WlROTnXr+6NEj/O9//8PWrVvRtWtXAEDjxo1x+vRpfPPNNwgNDYWHhwfy8/ORnp6uc3QnOTkZHh4epa5boVBAoVAYexOIiMgExCVlYfDSo7ifnYfarrZYMzoEniobqcuicmSyR3YKCgpQUFAAuVy3RAsLC2g0GgCPBytbWVlhz5492uVxcXG4efMmWrZsWa71EhGR6Tl3OwMDlsTgfnYefD3ssX5sSwadSkjSIzvZ2dmIj4/XPk9ISMDp06fh5OQEHx8ftG3bFlOnToWNjQ1q1KiB/fv346effsLs2bMBACqVCqNGjcKUKVPg5OQEBwcHvPnmm2jZsmWZZ2IREVHFdOKvVIxYfhxZeYUIqK7CypHBcKxiLXVZJAFJp57v27cP7dq1K9Y+bNgwrFixAklJSZg+fTp+//13pKamokaNGhg7diwmT54MmUwG4PFFBd9++238/PPPyMvLQ6dOnbBw4cInnsb6N049JyKqWP6Mv4/RK0/gUYEawTWdsGx4EOyVVlKXRQZW1u9vk7nOjpQYdoiIKo69l5Px+uqTyC/UoHU9FywZGgQbawupyyIjKOv3t8kOUCYiItLXr+cSMWndKRSoBV7xd8f8QU2hsGTQqewYdoiIqELYHHsbUzedgUYA3QK8MLtfAKwsTHYeDpUjhh0iIjJ7q4/cwPuR5wEA/YKqY1avxrCQyySuikwFww4REZm1pQevY+YvlwAAw1+siQ9f9YecQYf+gWGHiIjMkhAC3++Jx5w/rgAAXm9bB9PC6mtn6xIVYdghIiKzI4TAF1GXsXj/dQDA26+8gAnt6zLoUIkYdoiIyKxoNAIf77iAn2JuAADe7+qH0a1rS1wVmTKGHSIiMhtqjcC0zWexKfY2ZDLgs/BGGBTiI3VZZOIYdoiIyCwUqDV4a/1p/HI2EXIZ8G2/APRsWl3qssgMMOwQEZHJyy1QY8Lak/jjUgqsLGT4fkBTdG7kKXVZZCYYdoiIyKQ9zC/E2J9icSj+PhSWckQMCUQ7XzepyyIzwrBDREQmKyu3ACNXHMfxv9JQxdoCS4cF4cU6LlKXRWaGYYeIiExS+sN8vPbjMZy9nQF7pSVWjAhGYI2qUpdFZohhh4iITM69rDwMXXYUl5Oy4GRrjZ9GBqNhNZXUZZGZYtghIiKTkpjxCIN/OIrr93Pgaq/A2tEhqOduL3VZZMYYdoiIyGTcfPAQg5Yewe20R6jmaIM1o0NQ08VW6rLIzDHsEBGRSYhPycbgpUeQnJmHms5VsHp0CKpXrSJ1WVQBMOwQEZHkLt7NxNBlR/EgJx/13OywZnQI3ByUUpdFFUSZws7Zs2fLvMLGjRs/czFERFT5nLqZhmE/HkNmbiEaeDlg1agQONlaS10WVSBlCjtNmjSBTCaDEOKpd5RVq9UGKYyIiCq+o9cfYOSK48jJV6OZjyOWjwiGysZK6rKogpGXpVNCQgKuX7+OhIQEbN68GbVq1cLChQtx6tQpnDp1CgsXLkSdOnWwefNmY9dLREQVxP4r9zBs+THk5KvRsrYzVo0KYdAhoyjTkZ0aNWpo/79v3774/vvv0aVLF21b48aN4e3tjQ8++ADh4eEGL5KIiCqWXReS8ObaU8hXa9CuvisWDQmE0spC6rKogtJ7gPK5c+dQq1atYu21atXCxYsXDVIUERFVXNtO38GUDWeg1gh0buiB7wY0hbVlmU40ED0TvT9dfn5+mDVrFvLz87Vt+fn5mDVrFvz8/AxaHBERVSwbjt/CW+tPQ60R6NW0GuYNZNAh49P7yE5ERAS6deuG6tWra2denT17FjKZDDt27DB4gUREVDGs+DMBH+94fAZgcIgPPu3REHL5kye9EBmCTAgh9H1RTk4O1qxZg8uXLwN4fLRn0KBBsLU1z6tcZmZmQqVSISMjAw4ODlKXQ0RU4SzcF4+vouIAAKNb1cJ7Xf2eOruX6GnK+v2t15GdgoIC+Pr6YufOnRg7duxzF0lERBWbEALf/n4F86PjAQATO9TD5NB6DDpUrvQKO1ZWVsjNzTVWLUREVIEIIfDpzkv48c8EAMC0MF+88XIdiauiykjvUWHjx4/Hl19+icLCQmPUQ0REFYBaI/C/ree0QWdG9wYMOiQZvQcoHz9+HHv27MHvv/+ORo0aFRuns2XLFoMVR0RE5qdQrcE7G88g8vRdyGXAF70bo1+Qt9RlUSWmd9hxdHRE7969jVELERGZubxCNSb+fAq7LiTDUi7DnP5N0C3AS+qyqJLTO+wsX77cGHUQEZGZyy1QY9yqWOy/cg/WFnIsGNwMr/i7S10Wkf5jdgzpwIED6NatG7y8vCCTyRAZGamzXCaTlfj4+uuvtX1SU1MxePBgODg4wNHREaNGjUJ2dnY5bwkRUeWWnVeI4cuPYf+Ve1BaybFseBCDDpkMvY/sAMCmTZuwYcMG3Lx5U+dKygBw8uTJMq8nJycHAQEBGDlyJHr16lVseWJios7z3377DaNGjdI5jTZ48GAkJiZi9+7dKCgowIgRIzB27FisXbtWz60iIqJnkfGoAMOXH8Opm+mwU1jix+HNEVzLSeqyiLT0PrLz/fffY8SIEXB3d8epU6cQHBwMZ2dnXL9+HZ07d9ZrXZ07d8bMmTPRs2fPEpd7eHjoPLZt24Z27dqhdu3aAIBLly4hKioKS5cuRUhICFq1aoV58+Zh3bp1uHv3rr6bRkREenqQnYeBS47g1M10qGyssGZ0CIMOmRy9w87ChQuxZMkSzJs3D9bW1vjvf/+L3bt3Y+LEicjIyDBGjQCA5ORk/PLLLxg1apS2LSYmBo6OjggKCtK2hYaGQi6X4+jRo0arhYiIgOTMXAxYcgQXEzPhYmeNdWNbIMDbUeqyiIrRO+zcvHkTL774IgDAxsYGWVlZAIChQ4fi559/Nmx1/7By5UrY29vrnO5KSkqCm5ubTj9LS0s4OTkhKSmp1HXl5eUhMzNT50FERGV3O+0h+i2OwdWUbHg4KLF+XEv4efJ2O2Sa9A47Hh4eSE1NBQD4+PjgyJEjAICEhAQ8w222yuzHH3/E4MGDoVQqn3tds2bNgkql0j68vXn9ByKiskq4n4N+ETG48eAhvJ1ssPH1lqjjaid1WUSl0jvstG/fHtu3bwcAjBgxApMnT8Yrr7yC/v37lzr25nkdPHgQcXFxGD16tE67h4cHUlJSdNoKCwuRmpoKDw+PUtc3ffp0ZGRkaB+3bt0ySt1ERBVNXFIW+kbE4G5GLmq72mLDuJbwdqoidVlET6T3bKwlS5ZAo9EAeHzrCGdnZxw+fBjdu3fHuHHjDF4gACxbtgyBgYEICAjQaW/ZsiXS09MRGxuLwMBAAMDevXuh0WgQEhJS6voUCgUUCoVRaiUiqqjO3c7Aaz8eRdrDAvh62GPVqBC42vN3KZk+vcOOXC6HXP7/B4QGDBiAAQMGPNObZ2dnIz4+Xvs8ISEBp0+fhpOTE3x8fAA8vn37xo0b8e233xZ7vZ+fH8LCwjBmzBhERESgoKAAEyZMwIABA+DlxSt2EhEZyom/UjFi+XFk5RUioLoKK0cGw7GKtdRlEZWJ3mGnTZs2ePnll9G2bVu89NJLzzWG5sSJE2jXrp32+ZQpUwAAw4YNw4oVKwAA69atgxACAwcOLHEda9aswYQJE9ChQwfI5XL07t0b33///TPXREREuv6Mv4/RK0/gUYEawTWdsGx4EOyVVlKXRVRmMqHnqOKZM2fiwIEDOHz4MAoLCxEUFKQTfqpUMb9zt5mZmVCpVMjIyICDA2cTEBEV2Xs5Ga+vPon8Qg1a13PBkqFBsLG2kLosIgBl//7WO+wUKSwsxPHjx7F//37s27cPe/fuhVwuR25u7jMXLRWGHSKi4n45m4hJ606hUCPwir875g9qCoUlgw6ZjrJ+fz/T7SIA4Pr16zh37hzOnDmDs2fPwt7eHm3atHnW1RERkQnZHHsbUzedgUYA3QK8MLtfAKwsJL2dItEz0zvsDBo0CPv370deXh7atGmDtm3b4t1330Xjxo0hk8mMUSMREZWj1Udu4P3I8wCAfkHVMatXY1jI+fudzJfeYWfdunVwcXHB6NGj0b59e7Rq1cosx+kQEVFxSw9ex8xfLgEAhr9YEx++6g85gw6ZOb2PST548ABLly5Ffn4+pk+fDhcXF7z44ov43//+h99//90YNRIRkZEJIfDdH1e1QeeNl+vgo24MOlQxPPMA5SLx8fGYOXMm1qxZA41GA7Vabajayg0HKBNRZSaEwBdRl7F4/3UAwDsdX8CE9vUkroro6Yw2QPnBgwfaGVj79u3DxYsX4ejoiG7duqFt27bPVTQREZUvjUbg4x0X8FPMDQDAB6/6Y1SrWhJXRWRYeocdNzc3uLi4oHXr1hgzZgxefvllNGrUyBi1ERGREak1AtM2n8Wm2NuQyYDPwhthUIiP1GURGZzeYefs2bNo0KCBMWohIqJyUqDW4K31p/HL2UTIZcC3/QLQs2l1qcsiMgq9Byg3aNAAhYWF+OOPP7B48WJkZWUBAO7evYvs7GyDF0hERIaVW6DGG6tj8cvZRFhZyLBgUDMGHarQ9D6yc+PGDYSFheHmzZvIy8vDK6+8Ant7e3z55ZfIy8tDRESEMeokIiIDeJhfiLE/xeJQ/H0oLOWIGBKIdr5uUpdFZFR6H9mZNGkSgoKCkJaWBhsbG217z549sWfPHoMWR0REhpOZW4DXlh3Dofj7qGJtgeUjmjPoUKWg95GdgwcP4vDhw7C2ttZpr1mzJu7cuWOwwoiIyHDSH+bjtR+P4eztDNgrLbFiRDACa1SVuiyicqF32CntWjq3b9+Gvb29QYoiIiLDuZeVh6HLjuJyUhacbK3x08hgNKymkrosonKj92msjh07Yu7cudrnMpkM2dnZ+Oijj9ClSxdD1kZERM8pMeMR+i+OweWkLLjZK7B+bAsGHap09L6C8u3bt9GpUycIIXD16lUEBQXh6tWrcHFxwYEDB+DmZn7nf3kFZSKqiG4+eIhBS4/gdtojVHO0wZrRIajpYit1WUQGU9bv72e6XURhYSHWr1+PM2fOIDs7G82aNcPgwYN1BiybE4YdIqpo4lOyMXjpESRn5qGmcxWsGdMC1RzN83c0UWmMGnZKkpiYiM8++wzz5883xOrKFcMOEVUkF+9mYuiyo3iQk496bnZYMzoEbg5KqcsiMjij3BvrwoULiI6OhrW1Nfr16wdHR0fcv38fn332GSIiIlC7du3nLpyIiJ7dqZtpGPbjMWTmFqKBlwNWjQqBk631019IVIGVeYDy9u3b0bRpU0ycOBGvv/46goKCEB0dDT8/P1y6dAlbt27FhQsXjFkrERE9wdHrDzBk6VFk5haimY8j1o5pwaBDBD3CzsyZMzF+/HhkZmZi9uzZuH79OiZOnIhff/0VUVFRCAsLM2adRET0BPuv3MOw5ceQk69Gy9rOWDUqBCobK6nLIjIJZR6zo1KpEBsbi7p160KtVkOhUCAqKgqhoaHGrtHoOGaHiMzZrgtJeHPtKeSrNWhX3xWLhgRCaWUhdVlERmfwMTtZWVnaFVlYWMDGxoZjdIiIJLbt9B1M2XAGao1A54Ye+G5AU1hb6n0JNaIKTa8Byrt27YJK9fhiVBqNBnv27MH58+d1+nTv3t1w1RERUanWH7+Jd7ecgxBAr6bV8FWfxrC0YNAh+rcyn8aSy5/+D0gmk5V4KwlTx9NYRGRulv+ZgBk7LgIABof44NMeDSGXyySuiqh8Gfw0lkajMUhhRET0fBbui8dXUXEAgNGtauG9rn6QyRh0iEqj941AiYhIGkIIfPv7FcyPjgcATOxQD5ND6zHoED0Fww4RkRkQQuDTnZfw458JAIB3O/vi9bZ1JK6KyDww7BARmTi1RuD9yHP4+dgtAMAnPRrgtZY1pS2KyIww7BARmbBCtQbvbDyDyNN3IZcBX/RujH5B3lKXRWRWGHaIiExUXqEaE38+hV0XkmEpl2FO/yboFuAldVlEZueZLsiQnp6OpUuXYvr06UhNTQUAnDx5Enfu3DFocURElVVugRpjf4rFrgvJsLaQY9GQQAYdomek95Gds2fPIjQ0FCqVCn/99RfGjBkDJycnbNmyBTdv3sRPP/1kjDqJiCqN7LxCjF55HEeup0JpJccPrwWhdT1XqcsiMlt6H9mZMmUKhg8fjqtXr0KpVGrbu3TpggMHDui1rgMHDqBbt27w8vKCTCZDZGRksT6XLl1C9+7doVKpYGtri+bNm+PmzZva5bm5uRg/fjycnZ1hZ2eH3r17Izk5Wd/NIiIyCRkPCzB02VEcuZ4KO4UlfhoZwqBD9Jz0DjvHjx/HuHHjirVXq1YNSUlJeq0rJycHAQEBWLBgQYnLr127hlatWsHX1xf79u3D2bNn8cEHH+iErMmTJ2PHjh3YuHEj9u/fj7t376JXr176bRQRkQl4kJ2HgT8cwamb6VDZWGHN6BAE13KSuiwis6f3aSyFQoHMzMxi7VeuXIGrq35/fXTu3BmdO3cudfl7772HLl264KuvvtK21anz/9eVyMjIwLJly7B27Vq0b98eALB8+XL4+fnhyJEjaNGihV71EBFJJTkzF4OXHkV8SjZc7KyxalQI/Dx5+xoiQ9D7yE737t3xySefoKCgAMDj+2HdvHkT06ZNQ+/evQ1WmEajwS+//IIXXngBnTp1gpubG0JCQnROdcXGxqKgoAChoaHaNl9fX/j4+CAmJqbUdefl5SEzM1PnQUQkldtpD9FvcQziU7Lh4aDE+nEtGXSIDEjvsPPtt98iOzsbbm5uePToEdq2bYu6devC3t4en332mcEKS0lJQXZ2Nr744guEhYXh999/R8+ePdGrVy/s378fAJCUlARra2s4OjrqvNbd3f2Jp9RmzZoFlUqlfXh785oVRCSNhPs56BcRgxsPHsLbyQYbX2+JOq52UpdFVKHofRpLpVJh9+7dOHToEM6ePYvs7Gw0a9ZM5+iKIRTdeLRHjx6YPHkyAKBJkyY4fPgwIiIi0LZt22de9/Tp0zFlyhTt88zMTAYeIip3cUlZGLz0KO5n56GOqy3WjG4BD5Xy6S8kIr0880UFW7VqhVatWhmyFh0uLi6wtLSEv7+/Trufnx8OHToEAPDw8EB+fj7S09N1ju4kJyfDw8Oj1HUrFAooFAqj1E1EVBbnbmfgtR+PIu1hAXw97LF6dAhc7Ph7icgY9A4733//fYntMpkMSqUSdevWRZs2bWBhYfFchVlbW6N58+aIi4vTab9y5Qpq1KgBAAgMDISVlRX27NmjHS8UFxeHmzdvomXLls/1/kRExnLir1SMWH4cWXmFCKiuwsqRwXCsYi11WUQVlt5hZ86cObh37x4ePnyIqlWrAgDS0tJQpUoV2NnZISUlBbVr10Z0dPRTTw1lZ2cjPj5e+zwhIQGnT5+Gk5MTfHx8MHXqVPTv3x9t2rRBu3btEBUVhR07dmDfvn0AHp9SGzVqFKZMmQInJyc4ODjgzTffRMuWLTkTi4hM0p/x9zF65Qk8KlAjuKYTlg0Pgr3SSuqyiCo2oae1a9eKl19+WcTHx2vbrl69Ktq3by/WrVsnbt26JV566SXRu3fvp64rOjpaACj2GDZsmLbPsmXLRN26dYVSqRQBAQEiMjJSZx2PHj0S//nPf0TVqlVFlSpVRM+ePUViYqJe25SRkSEAiIyMDL1eR0Skjz2XkkS9934VNabtFEOWHhEP8wqlLonIrJX1+1smhBD6hKM6depg8+bNaNKkiU77qVOn0Lt3b1y/fh2HDx9G7969kZiYaJBAZmyZmZlQqVTIyMiAgwOnexKR4f1yNhGT1p1CoUbgFX93zB/UFArL5zvdT1TZlfX7W+/TWImJiSgsLCzWXlhYqJ3u7eXlhaysLH1XTURUIW2OvY2pm85AI4BuAV6Y3S8AVhbPdB9mInoGev9ra9euHcaNG4dTp05p206dOoU33nhDexXjc+fOoVatWoarkojITK06cgNvb3wcdPoFVcfc/k0YdIjKmd7/4pYtWwYnJycEBgZqp3AHBQXByckJy5YtAwDY2dnh22+/NXixRETm5IcD1/FB5HkAwPAXa+KLXo1hIZdJXBVR5aP3mJ0ily9fxpUrVwAA9evXR/369Q1aWHnimB0iMiQhBL7fE485fzz+HfnGy3Xw3071IZMx6BAZktHG7BTx9fWFr6/vs76ciKhCEkLgi6jLWLz/OgDgnY4vYEL7ehJXRVS5PVPYuX37NrZv346bN28iPz9fZ9ns2bMNUhgRkbnRaAQ+3nEBP8XcAAB88Ko/RrXi+EUiqekddvbs2YPu3bujdu3auHz5Mho2bIi//voLQgg0a9bMGDUSEZk8tUZg2uaz2BR7GzIZ8Fl4IwwK8ZG6LCLCMwxQnj59Ot555x2cO3cOSqUSmzdvxq1bt9C2bVv07dvXGDUSEZm0ArUGE9edwqbY27CQyzC7XwCDDpEJ0TvsXLp0Ca+99hoAwNLSEo8ePYKdnR0++eQTfPnllwYvkIjIlOUWqPHG6lj8cjYRVhYyLBjUFD2bVpe6LCL6B73Djq2trXacjqenJ65du6Zddv/+fcNVRkRk4h7mF2L0yhP441IKFJZyLBkahLCGnlKXRUT/oveYnRYtWuDQoUPw8/NDly5d8Pbbb+PcuXPYsmULb75JRJVGZm4BRi4/jhM30lDF2gJLhwXhxTouUpdFRCXQO+zMnj0b2dnZAIAZM2YgOzsb69evR7169TgTi4gqhbScfAxbfgxnb2fAXmmJFSOCEVijqtRlEVEp9Ao7arUat2/fRuPGjQE8PqUVERFhlMKIiExRSlYuhi49hrjkLDjZWuOnkcFoWE0ldVlE9AR6jdmxsLBAx44dkZaWZqx6iIhMVmLGIwxYfARxyVlws1dg/dgWDDpEZkDvAcoNGzbE9evXjVELEZHJuvngIfpGxOD6/RxUc7TBhnEtUc/dXuqyiKgM9A47M2fOxDvvvIOdO3ciMTERmZmZOg8iooomPiUbfRcfxu20R6jpXAUbXm+Jmi62UpdFRGWk941A5fL/z0f/vKmdEAIymQxqtdpw1ZUT3giUiEpz8W4mhi47igc5+XjB3Q6rR4XAzUEpdVlEBCPeCDQ6Ovq5CiMiMhenbqZh2I/HkJlbiIbVHPDTyBA42VpLXRYR6UnvsNO2bVtj1EFEZFKOXn+AkSuOIydfjcAaVbF8RHM4KK2kLouInoHeY3YA4ODBgxgyZAhefPFF3LlzBwCwatUqHDp0yKDFERFJYf+Vexi2/Bhy8tV4sY4zfhoZzKBDZMb0DjubN29Gp06dYGNjg5MnTyIvLw8AkJGRgc8//9zgBRIRladdF5IwZuUJ5BZo0K6+K34c3hy2Cr0PghORCXmm2VgRERH44YcfYGX1/3/pvPTSSzh58qRBiyMiKk/bTt/Bf9acRL5ag84NPbB4aBCUVhZSl0VEz0nvP1fi4uLQpk2bYu0qlQrp6emGqImIqNytP34T7245ByGAXk2r4as+jWFp8Uxn+onIxOj9L9nDwwPx8fHF2g8dOoTatWsbpCgiovK0/M8ETNv8OOgMDvHBN30DGHSIKhC9/zWPGTMGkyZNwtGjRyGTyXD37l2sWbMG77zzDt544w1j1EhEZDQLouMxY8dFAMDoVrUwM7wh5HLZU15FROZE79NY7777LjQaDTp06ICHDx+iTZs2UCgUeOedd/Dmm28ao0YiIoMTQuDb369gfvTjI9UTO9TD5NB6OhdLJaKKQe8rKBfJz89HfHw8srOz4e/vDzs7O0PXVm54BWWiykUIgU93XsKPfyYAAN7t7IvX29aRuCoi0pfRrqC8evVq9OrVC1WqVIG/v/9zFUlEVN7UGoH3I8/h52O3AACf9GiA11rWlLYoIjIqvcfsTJ48GW5ubhg0aBB+/fVXs7wXFhFVToVqDd7ecBo/H7sFuQz4uk9jBh2iSkDvsJOYmIh169ZBJpOhX79+8PT0xPjx43H48GFj1EdEZBB5hWqMX3sSkafvwlIuw3cDmqJvkLfUZRFROXjmMTsA8PDhQ2zduhVr167FH3/8gerVq+PatWuGrK9ccMwOUcWWW6DGuFWx2H/lHqwt5Fg4uBlC/d2lLouInpPRxuz8U5UqVdCpUyekpaXhxo0buHTp0vOsjqhM1BqBYwmpSMnKhZu9EsG1nGDBqcL0D//8jNgrrbB4fzyOJqRBaSXHD68FoXU9V6lLJKJy9Exhp+iIzpo1a7Bnzx54e3tj4MCB2LRpk6HrI9IRdT4RM3ZcRGJGrrbNU6XER938EdbQU8LKyFSU9BkBAKWlHD+NDEFwLSeJKiMiqeg9ZmfAgAFwc3PD5MmTUbt2bezbtw/x8fH49NNP4evrq9e6Dhw4gG7dusHLywsymQyRkZE6y4cPHw6ZTKbzCAsL0+mTmpqKwYMHw8HBAY6Ojhg1ahSys7P13axKSa0RiLn2ANtO30HMtQdQa575jGa5iDqfiDdWnyz2JZaUkYs3Vp9E1PlEiSojU1HaZwQAcgs1SM3Jk6AqIpKa3kd2LCwssGHDBnTq1AkWFro3yDt//jwaNmxY5nXl5OQgICAAI0eORK9evUrsExYWhuXLl2ufKxQKneWDBw9GYmIidu/ejYKCAowYMQJjx47F2rVr9diqyseUj5DkF2qQk1eI7H88Mh8V4N3N51BSHCtqe2fjWZy7kwE5LwpXKWmEwMrDf5X4GQEAGYAZOy7iFX8PnvYkqmSea4AyAGRlZeHnn3/G0qVLERsb+8xT0WUyGbZu3Yrw8HBt2/Dhw5Genl7siE+RS5cuwd/fH8ePH0dQUBAAICoqCl26dMHt27fh5eVVpveubAOUi/76/fcPvujX/6IhzfQOPCUFlOy8QmTnFuq25xYiJ78QWTrtamTnFSAnT43s3ELkqzUG2U6ikvw8pgVa1nGWugwiMgCjD1A+cOAAli1bhs2bN8PLywu9evXCggULnnV1pdq3bx/c3NxQtWpVtG/fHjNnzoSz8+NfVDExMXB0dNQGHQAIDQ2FXC7H0aNH0bNnzxLXmZeXh7y8/z+cnZmZafC6TZVaIzBjx8UnHiF5d8s5pObk42G+WtKAorSSw05hCTuFJQrVArfTHz31Na3ruaC2i63BayHTd/1+Dg5evf/UfilZxU9xEVHFplfYSUpKwooVK7Bs2TJkZmaiX79+yMvLQ2RkpFGuphwWFoZevXqhVq1auHbtGv73v/+hc+fOiImJgYWFBZKSkuDm5qbzGktLSzg5OSEpKanU9c6aNQszZswweL3m4FhCaonjGf4p/WEB/rf1/DOt/3FAsYKdwgJ2SkvYWj8OK3ZKS9gqLGGvePzfohBT1F703FZhAXuFFWwVFjp3nY659gADfzjy1Pf/z8t1+Vd7JRVz7UGZwo6bvbIcqiEiU1LmsNOtWzccOHAAXbt2xdy5cxEWFgYLCwtEREQYrbgBAwZo/79Ro0Zo3Lgx6tSpg3379qFDhw7PvN7p06djypQp2ueZmZnw9q4cFxcr61+1Db0cUMfN7v9DSVFIUf7j//8RWOysLYsFFEMKruUET5USSRm5JR6VkgHwUCk506YS42eEiEpT5rDz22+/YeLEiXjjjTdQr149Y9ZUqtq1a8PFxQXx8fHo0KEDPDw8kJKSotOnsLAQqamp8PDwKHU9CoWi2EDnyqKsf9W+19XfpI6QWMhl+KibP95YfRIyQOfLrGis0Ufd/DnwtBLjZ4SISlPmP8MPHTqErKwsBAYGIiQkBPPnz8f9+08/ZGxIt2/fxoMHD+Dp+XjwbMuWLZGeno7Y2Fhtn71790Kj0SAkJKRcazMXRX/9lvbrXobHs7JM8a/fsIaeWDSkGTxUuoHNQ6V8pkHVVPHwM0JEJdF7NlZOTg7Wr1+PH3/8EceOHYNarcbs2bMxcuRI2Nvb6/Xm2dnZiI+PBwA0bdoUs2fPRrt27eDk5AQnJyfMmDEDvXv3hoeHB65du4b//ve/yMrKwrlz57RHZjp37ozk5GRERERop54HBQXpNfWcs7Eee57ZWOWJV1Cmp+FnhKhyKOv393NNPY+Li8OyZcuwatUqpKen45VXXsH27dvL/Pp9+/ahXbt2xdqHDRuGRYsWITw8HKdOnUJ6ejq8vLzQsWNHfPrpp3B3//972qSmpmLChAnYsWMH5HI5evfuje+//x52dnZlrqOyhR0AeHfLWaw7dkunzVSus0NERFQW5RJ2iqjVauzYsQM//vijXmHHVFTGsNM34jCO/5WGISE+aF7LiX/9EhGR2SmXG4EWsbCwQHh4uM4FAcl03U57iON/pUEmAya0r1dsfAMREVFFYpx5wmTStp+5CwBoUcuZQYeIiCo8hp1KaNupx2GnR5Oy3U6DiIjInDHsVDKXkzIRl5wFaws5OnMgMhERVQIMO5XMttOPj+q8XN8VqipWEldDRERkfAw7lYhGI7D977AT3rSaxNUQERGVD4adSiT2ZhrupD+CncIS7X3dnv4CIiKiCoBhpxKJPHUHABDW0ANKKwuJqyEiIiofDDuVRH6hBr+cSwTAWVhERFS5MOxUEgev3kP6wwK42CnwYh0XqcshIiIqNww7lUTRLKxuAZ68JQQREVUqDDuVQE5eIXZfTAYA9GjCWVhERFS5MOxUArsvJuNRgRo1nasgoLpK6nKIiIjKFcNOJRB5+vEsrO5NqkEm4yksIiKqXBh2KrgH2Xk4ePU+AM7CIiKiyolhp4L75Vwi1BqBRtVUqONqJ3U5RERE5Y5hp4IrmoXFozpERFRZMexUYLdSHyL2RhpkMqBbAMMOERFVTgw7Fdj2M4+P6rxYxxnuDkqJqyEiIpIGw04FJYTQ3gurRwCvrUNERJUXw04FdSkxC1dTsmFtKUdYIw+pyyEiIpIMw04Fte3va+u0r+8GB6WVxNUQERFJh2GnAtJohHa8TnhTDkwmIqLKjWGnAjr+VyoSM3Jhr7TEy/XdpC6HiIhIUgw7FVDk39fW6dzQA0orC4mrISIikhbDTgWTX6jBr+cSAfAO50RERADDToWz/8o9ZDwqgJu9Ai1qO0tdDhERkeQYdiqYollY3QK8YCHnHc6JiIgYdiqQ7LxC/HEpGQAQzlNYREREABh2KpTfLyQht0CD2i62aFjNQepyiIiITALDTgVSNAurexMvyGQ8hUVERAQw7FQY97Ly8Gf8fQCchUVERPRPkoadAwcOoFu3bvDyenwkIjIystS+r7/+OmQyGebOnavTnpqaisGDB8PBwQGOjo4YNWoUsrOzjVu4Cfrl7F2oNQIB1VWo5WIrdTlEREQmQ9Kwk5OTg4CAACxYsOCJ/bZu3YojR47Ay6v4rQ8GDx6MCxcuYPfu3di5cycOHDiAsWPHGqtkk7Xt79tD8KgOERGRLksp37xz587o3LnzE/vcuXMHb775Jnbt2oWuXbvqLLt06RKioqJw/PhxBAUFAQDmzZuHLl264JtvvikxHFVENx7k4NTNdMhlwKsBnlKXQ0REZFJMesyORqPB0KFDMXXqVDRo0KDY8piYGDg6OmqDDgCEhoZCLpfj6NGjpa43Ly8PmZmZOg9ztv3vgckv1XWBm71S4mqIiIhMi0mHnS+//BKWlpaYOHFiicuTkpLg5qZ7o0tLS0s4OTkhKSmp1PXOmjULKpVK+/D29jZo3eVJCIHIvy8k2D2gchzJIiIi0ofJhp3Y2Fh89913WLFihcGnUU+fPh0ZGRnax61btwy6/vJ04W4mrt3LgbWlHGENPaQuh4iIyOSYbNg5ePAgUlJS4OPjA0tLS1haWuLGjRt4++23UbNmTQCAh4cHUlJSdF5XWFiI1NRUeHiU/sWvUCjg4OCg8zBXRbeHCPVzg73SSuJqiIiITI+kA5SfZOjQoQgNDdVp69SpE4YOHYoRI0YAAFq2bIn09HTExsYiMDAQALB3715oNBqEhISUe83lTa0R2M5ZWERERE8kadjJzs5GfHy89nlCQgJOnz4NJycn+Pj4wNlZ967dVlZW8PDwQP369QEAfn5+CAsLw5gxYxAREYGCggJMmDABAwYMqBQzsY4lpCI5Mw8OSku8XN9V6nKIiIhMkqSnsU6cOIGmTZuiadOmAIApU6agadOm+PDDD8u8jjVr1sDX1xcdOnRAly5d0KpVKyxZssRYJZuUolNYXRp5QmFpIXE1REREpknSIzsvv/wyhBBl7v/XX38Va3NycsLatWsNWJV5yCtU49dziQAe3wuLiIiISmayA5TpyfbF3UNmbiE8HJQIqeX89BcQERFVUgw7ZqroQoLdAjxhIecdzomIiErDsGOGsnIL8MelZACchUVERPQ0DDtmaNeFZOQValDH1RYNvMz3GkFERETlgWHHDBXNwgpvUs3gV5cmIiKqaBh2zExKVi7+jL8PgLOwiIiIyoJhx8zsPJMIjQCaeDuihrOt1OUQERGZPIYdM7Pt79tDhPOoDhERUZkw7JiRhPs5OHMrHRZyGbo2ZtghIiIqC4YdM1J0bZ2X6rrA1V4hcTVERETmgWHHTAghtLOwegTwqA4REVFZMeyYifN3MnH9fg4UlnJ0aughdTlERERmg2HHTET+fVQn1N8ddgpJ799KRERkVhh2zIBaI7BDOwuLt4cgIiLSB8OOGTh6/QFSsvKgsrFC2xdcpS6HiIjIrDDsmIGiU1hdGnnC2pI/MiIiIn3wm9PE5Rao8dv5JABAD15IkIiISG8MOyZuX1wKsnIL4alSIrimk9TlEBERmR2GHRO37e8LCXYP8IJczjucExER6Ythx4Rl5hZgz+UUAEAPzsIiIiJ6Jgw7JizqfBLyCzWo52YHP097qcshIiIySww7Jqzo9hDhTatBJuMpLCIiomfBsGOiUjJzcfjaAwCPx+sQERHRs2HYMVHbz9yFEEBgjarwdqoidTlERERmi2HHRG3/+/YQvLYOERHR82HYMUHX72Xj7O0MWMhl6NLIU+pyiIiIzBrDjgkqurZO63oucLFTSFwNERGReWPYMTFCCO0sLJ7CIiIien4MOybm7O0M/PXgIZRWcnT095C6HCIiIrPHsGNiiu5w/oq/B2wVlhJXQ0REZP4YdkyIWiOw40wiACCcp7CIiIgMgmHHhMRce4D72XlwrGKF1vVcpS6HiIioQmDYMSFFp7C6NvKEtSV/NERERIYg6TfqgQMH0K1bN3h5eUEmkyEyMlJn+ccffwxfX1/Y2tqiatWqCA0NxdGjR3X6pKamYvDgwXBwcICjoyNGjRqF7OzsctwKw8gtUCPqfBIA3uGciIjIkCQNOzk5OQgICMCCBQtKXP7CCy9g/vz5OHfuHA4dOoSaNWuiY8eOuHfvnrbP4MGDceHCBezevRs7d+7EgQMHMHbs2PLaBIPZezkF2XmFqOZog6AaVaUuh4iIqMKQCSGE1EUAgEwmw9atWxEeHl5qn8zMTKhUKvzxxx/o0KEDLl26BH9/fxw/fhxBQUEAgKioKHTp0gW3b9+Gl1fZBvkWrTcjIwMODg6G2By9jVt1ArsuJOP1tnXwbmdfSWogIiIyJ2X9/jabgSH5+flYsmQJVCoVAgICAAAxMTFwdHTUBh0ACA0NhVwuL3a665/y8vKQmZmp85BSxsMCRF9+fLQqvClnYRERERmSyYednTt3ws7ODkqlEnPmzMHu3bvh4uICAEhKSoKbm5tOf0tLSzg5OSEpKanUdc6aNQsqlUr78Pb2Nuo2PE3UhUTkqzWo724PXw9pjiwRERFVVCYfdtq1a4fTp0/j8OHDCAsLQ79+/ZCSkvJc65w+fToyMjK0j1u3bhmo2mcTeervO5zzqA4REZHBmXzYsbW1Rd26ddGiRQssW7YMlpaWWLZsGQDAw8OjWPApLCxEamoqPDxKv9WCQqGAg4ODzkMqSRm5OJLwAADQPYBhh4iIyNBMPuz8m0ajQV5eHgCgZcuWSE9PR2xsrHb53r17odFoEBISIlWJetlx5i6EAJrXrIrqVatIXQ4REVGFI+nNl7KzsxEfH699npCQgNOnT8PJyQnOzs747LPP0L17d3h6euL+/ftYsGAB7ty5g759+wIA/Pz8EBYWhjFjxiAiIgIFBQWYMGECBgwYUOaZWFLbdubxhQS789o6RERERiFp2Dlx4gTatWunfT5lyhQAwLBhwxAREYHLly9j5cqVuH//PpydndG8eXMcPHgQDRo00L5mzZo1mDBhAjp06AC5XI7evXvj+++/L/dteRbxKdk4fycTlnIZujbylLocIiKiCknSsPPyyy/jSZf52bJly1PX4eTkhLVr1xqyrHKz/e/bQ7R5wRVOttYSV0NERFQxmd2YnYpCCIHI03/PwuIdzomIiIyGYUcip2+l42bqQ9hYWeAVf3epyyEiIqqwGHYksu3vozodG7ijirWkZxOJiIgqNIYdCRSqNdh59nHYCecsLCIiIqNi2JHA4WsPcD87H0621mhVz0XqcoiIiCo0hh0JRP49C6trI09YWfBHQEREZEz8pi1nuQVq7Dr/+CalnIVFRERkfAw75eyPS8nIyVejelUbBNaoKnU5REREFR7DTjkrmoXVPcALMplM4mqIiIgqPoadcpT+MB/74h7fpT28KWdhERERlQeGnXL02/kkFKgFfD3s8YK7vdTlEBERVQoMO+Uo8tTjWVg8qkNERFR+GHbKyd30Rzj2VyoAoFsAZ2ERERGVF4adcrLjzF0IAQTXckI1RxupyyEiIqo0GHbKyTbe4ZyIiEgSDDvl4GpyFi4mZsLKQoYuDT2lLoeIiKhSYdgpB0VHddq+4IqqttYSV0NERFS5MOwYmRAC2848noXVg3c4JyIiKneWUhdQUak1AscSUnE04QFupT5CFSs5Qv3cpS6LiIio0mHYMYKo84mYseMiEjNytW0CwP4rKQjjmB0iIqJyxdNYBhZ1PhFvrD6pE3QA4FGBBm+sPomo84kSVUZERFQ5MewYkFojMGPHRYgn9Jmx4yLUmif1ICIiIkNi2DGgYwmpxY7o/JMAkJiRi2MJqeVXFBERUSXHsGNAKVmlB51n6UdERETPj2HHgNzslQbtR0RERM+PYceAgms5wVOlhKyU5TIAniolgms5lWdZRERElRrDjgFZyGX4qJs/ABQLPEXPP+rmDwt5aXGIiIiIDI1hx8DCGnpi0ZBm8FDpnqryUCmxaEgzXmeHiIionPGigkYQ1tATr/h74FhCKlKycuFm//jUFY/oEBERlT+GHSOxkMvQso6z1GUQERFVejyNRURERBUaww4RERFVaJKGnQMHDqBbt27w8vKCTCZDZGSkdllBQQGmTZuGRo0awdbWFl5eXnjttddw9+5dnXWkpqZi8ODBcHBwgKOjI0aNGoXs7Oxy3hIiIiIyVZKGnZycHAQEBGDBggXFlj18+BAnT57EBx98gJMnT2LLli2Ii4tD9+7ddfoNHjwYFy5cwO7du7Fz504cOHAAY8eOLa9NICIiIhMnE0KYxF0pZTIZtm7divDw8FL7HD9+HMHBwbhx4wZ8fHxw6dIl+Pv74/jx4wgKCgIAREVFoUuXLrh9+za8vLzK9N6ZmZlQqVTIyMiAg4ODITaHiIiIjKys399mNWYnIyMDMpkMjo6OAICYmBg4Ojpqgw4AhIaGQi6X4+jRoxJVSURERKbEbKae5+bmYtq0aRg4cKA2vSUlJcHNzU2nn6WlJZycnJCUlFTquvLy8pCXl6d9npmZaZyiiYiISHJmcWSnoKAA/fr1gxACixYteu71zZo1CyqVSvvw9vY2QJVERERkikw+7BQFnRs3bmD37t065+Q8PDyQkpKi07+wsBCpqanw8PAodZ3Tp09HRkaG9nHr1i2j1U9ERETSMunTWEVB5+rVq4iOjoazs+4ViVu2bIn09HTExsYiMDAQALB3715oNBqEhISUul6FQgGFQqF9XjRGm6eziIiIzEfR9/bT5lpJGnays7MRHx+vfZ6QkIDTp0/DyckJnp6e6NOnD06ePImdO3dCrVZrx+E4OTnB2toafn5+CAsLw5gxYxAREYGCggJMmDABAwYMKPNMLADIysoCAJ7OIiIiMkNZWVlQqVSlLpd06vm+ffvQrl27Yu3Dhg3Dxx9/jFq1apX4uujoaLz88ssAHl9UcMKECdixYwfkcjl69+6N77//HnZ2dmWuQ6PR4O7du7C3t4dM9uw368zMzIS3tzdu3brFKexGxn1dfrivyw/3dfnhvi4/xtzXQghkZWXBy8sLcnnpI3NM5jo7FQGv11N+uK/LD/d1+eG+Lj/c1+XHFPa1yQ9QJiIiInoeDDtERERUoTHsGJBCocBHH32kM9OLjIP7uvxwX5cf7uvyw31dfkxhX3PMDhEREVVoPLJDREREFRrDDhEREVVoDDtERERUoTHsEBERUYXGsPMECxYsQM2aNaFUKhESEoJjx449sf/GjRvh6+sLpVKJRo0a4ddff9VZLoTAhx9+CE9PT9jY2CA0NBRXr1415iaYDUPu64KCAkybNg2NGjWCra0tvLy88Nprr+Hu3bvG3gyzYejP9j+9/vrrkMlkmDt3roGrNk/G2NeXLl1C9+7doVKpYGtri+bNm+PmzZvG2gSzYeh9nZ2djQkTJqB69eqwsbGBv78/IiIijLkJZkOffX3hwgX07t0bNWvWfOLvBn1/fnoRVKJ169YJa2tr8eOPP4oLFy6IMWPGCEdHR5GcnFxi/z///FNYWFiIr776Sly8eFG8//77wsrKSpw7d07b54svvhAqlUpERkaKM2fOiO7du4tatWqJR48elddmmSRD7+v09HQRGhoq1q9fLy5fvixiYmJEcHCwCAwMLM/NMlnG+GwX2bJliwgICBBeXl5izpw5Rt4S02eMfR0fHy+cnJzE1KlTxcmTJ0V8fLzYtm1bqeusLIyxr8eMGSPq1KkjoqOjRUJCgli8eLGwsLAQ27ZtK6/NMkn67utjx46Jd955R/z888/Cw8OjxN8N+q5TXww7pQgODhbjx4/XPler1cLLy0vMmjWrxP79+vUTXbt21WkLCQkR48aNE0IIodFohIeHh/j666+1y9PT04VCoRA///yzEbbAfBh6X5fk2LFjAoC4ceOGYYo2Y8ba37dv3xbVqlUT58+fFzVq1GDYEcbZ1/379xdDhgwxTsFmzBj7ukGDBuKTTz7R6dOsWTPx3nvvGbBy86Pvvv6n0n43PM86y4KnsUqQn5+P2NhYhIaGatvkcjlCQ0MRExNT4mtiYmJ0+gNAp06dtP0TEhKQlJSk00elUiEkJKTUdVYGxtjXJcnIyIBMJoOjo6NB6jZXxtrfGo0GQ4cOxdSpU9GgQQPjFG9mjLGvNRoNfvnlF7zwwgvo1KkT3NzcEBISgsjISKNthzkw1uf6xRdfxPbt23Hnzh0IIRAdHY0rV66gY8eOxtkQM/As+1qKdf4bw04J7t+/D7VaDXd3d512d3d3JCUllfiapKSkJ/Yv+q8+66wMjLGv/y03NxfTpk3DwIEDK/0N/4y1v7/88ktYWlpi4sSJhi/aTBljX6ekpCA7OxtffPEFwsLC8Pvvv6Nnz57o1asX9u/fb5wNMQPG+lzPmzcP/v7+qF69OqytrREWFoYFCxagTZs2ht8IM/Es+1qKdf6bpUHWQmSiCgoK0K9fPwghsGjRIqnLqZBiY2Px3Xff4eTJk5DJZFKXU6FpNBoAQI8ePTB58mQAQJMmTXD48GFERESgbdu2UpZX4cybNw9HjhzB9u3bUaNGDRw4cADjx4+Hl5dXsaNCZNp4ZKcELi4usLCwQHJysk57cnIyPDw8SnyNh4fHE/sX/VefdVYGxtjXRYqCzo0bN7B79+5Kf1QHMM7+PnjwIFJSUuDj4wNLS0tYWlrixo0bePvtt1GzZk2jbIc5MMa+dnFxgaWlJfz9/XX6+Pn5VerZWMbY148ePcL//vc/zJ49G926dUPjxo0xYcIE9O/fH998841xNsQMPMu+lmKd/8awUwJra2sEBgZiz5492jaNRoM9e/agZcuWJb6mZcuWOv0BYPfu3dr+tWrVgoeHh06fzMxMHD16tNR1VgbG2NfA/wedq1ev4o8//oCzs7NxNsDMGGN/Dx06FGfPnsXp06e1Dy8vL0ydOhW7du0y3saYOGPsa2trazRv3hxxcXE6fa5cuYIaNWoYeAvMhzH2dUFBAQoKCiCX635NWlhYaI+wVUbPsq+lWGcxBhnmXAGtW7dOKBQKsWLFCnHx4kUxduxY4ejoKJKSkoQQQgwdOlS8++672v5//vmnsLS0FN988424dOmS+Oijj0qceu7o6Ci2bdsmzp49K3r06MGp58Lw+zo/P190795dVK9eXZw+fVokJiZqH3l5eZJsoykxxmf73zgb6zFj7OstW7YIKysrsWTJEnH16lUxb948YWFhIQ4ePFju22dKjLGv27ZtKxo0aCCio6PF9evXxfLly4VSqRQLFy4s9+0zJfru67y8PHHq1Clx6tQp4enpKd555x1x6tQpcfXq1TKv83kx7DzBvHnzhI+Pj7C2thbBwcHiyJEj2mVt27YVw4YN0+m/YcMG8cILLwhra2vRoEED8csvv+gs12g04oMPPhDu7u5CoVCIDh06iLi4uPLYFJNnyH2dkJAgAJT4iI6OLqctMm2G/mz/G8PO/zPGvl62bJmoW7euUCqVIiAgQERGRhp7M8yCofd1YmKiGD58uPDy8hJKpVLUr19ffPvtt0Kj0ZTH5pg0ffZ1ab+T27ZtW+Z1Pi+ZEEIY5hgRERERkenhmB0iIiKq0Bh2iIiIqEJj2CEiIqIKjWGHiIiIKjSGHSIiIqrQGHaIiIioQmPYISIiogqNYYeIzFrNmjUxd+5cqcsgIhPGsENETzV8+HCEh4dLXUaJjh8/jrFjxxr9fWrWrAmZTAaZTIYqVaqgUaNGWLp0qd7rkclkiIyMNHyBRFQqhh0iMkkFBQVl6ufq6ooqVaoYuZrHPvnkEyQmJuL8+fMYMmQIxowZg99++61c3puInh3DDhE9t/Pnz6Nz586ws7ODu7s7hg4divv372uXR0VFoVWrVnB0dISzszNeffVVXLt2Tbv8r7/+gkwmw/r169G2bVsolUqsWbNGe0Tpm2++gaenJ5ydnTF+/HidIPTv01gymQxLly5Fz549UaVKFdSrVw/bt2/XqXf79u2oV68elEol2rVrh5UrV0ImkyE9Pf2J22lvbw8PDw/Url0b06ZNg5OTE3bv3q1dfvz4cbzyyitwcXGBSqVC27ZtcfLkSZ1aAaBnz56QyWTa5wCwbds2NGvWDEqlErVr18aMGTNQWFhYlt1PRE/BsENEzyU9PR3t27dH06ZNceLECURFRSE5ORn9+vXT9snJycGUKVNw4sQJ7NmzB3K5HD179oRGo9FZ17vvvotJkybh0qVL6NSpEwAgOjoa165dQ3R0NFauXIkVK1ZgxYoVT6xpxowZ6NevH86ePYsuXbpg8ODBSE1NBQAkJCSgT58+CA8Px5kzZzBu3Di89957em2zRqPB5s2bkZaWBmtra217VlYWhg0bhkOHDuHIkSOoV68eunTpgqysLACPwxAALF++HImJidrnBw8exGuvvYZJkybh4sWLWLx4MVasWIHPPvtMr7qIqBQGu6UoEVVYw4YNEz169Chx2aeffio6duyo03br1i0BQMTFxZX4mnv37gkA4ty5c0KI/78r8ty5c4u9b40aNURhYaG2rW/fvqJ///7a5/++wzoA8f7772ufZ2dnCwDit99+E0IIMW3aNNGwYUOd93nvvfcEAJGWllbyDvj7faytrYWtra2wtLQUAISTk5O4evVqqa9Rq9XC3t5e7NixQ6e+rVu36vTr0KGD+Pzzz3XaVq1aJTw9PUtdNxGVHY/sENFzOXPmDKKjo2FnZ6d9+Pr6AoD2VNXVq1cxcOBA1K5dGw4ODtrTNzdv3tRZV1BQULH1N2jQABYWFtrnnp6eSElJeWJNjRs31v6/ra0tHBwctK+Ji4tD8+bNdfoHBweXaVunTp2K06dPY+/evQgJCcGcOXNQt25d7fLk5GSMGTMG9erVg0qlgoODA7Kzs4tt57+dOXMGn3zyic4+HDNmDBITE/Hw4cMy1UZEpbOUugAiMm/Z2dno1q0bvvzyy2LLPD09AQDdunVDjRo18MMPP8DLywsajQYNGzZEfn6+Tn9bW9ti67CystJ5LpPJip3+MsRrysLFxQV169ZF3bp1sXHjRjRq1AhBQUHw9/cHAAwbNgwPHjzAd999hxo1akChUKBly5bFtvPfsrOzMWPGDPTq1avYMqVS+dx1E1V2DDtE9FyaNWuGzZs3o2bNmrC0LP4r5cGDB4iLi8MPP/yA1q1bAwAOHTpU3mVq1a9fH7/++qtOW9HYGX14e3ujf//+mD59OrZt2wYA+PPPP7Fw4UJ06dIFAHDr1i2dgdrA4yCmVqt12po1a4a4uDido0REZDg8jUVEZZKRkYHTp0/rPG7duoXx48cjNTUVAwcOxPHjx3Ht2jXs2rULI0aMgFqtRtWqVeHs7IwlS5YgPj4ee/fuxZQpUyTbjnHjxuHy5cuYNm0arly5gg0bNmgHPMtkMr3WNWnSJOzYsQMnTpwAANSrVw+rVq3CpUuXcPToUQwePBg2NjY6r6lZsyb27NmDpKQkpKWlAQA+/PBD/PTTT5gxYwYuXLiAS5cuYd26dXj//feff4OJiGGHiMpm3759aNq0qc5jxowZ8PLywp9//gm1Wo2OHTuiUaNGeOutt+Do6Ai5XA65XI5169YhNjYWDRs2xOTJk/H1119Lth21atXCpk2bsGXLFjRu3BiLFi3SzsZSKBR6rcvf3x8dO3bEhx9+CABYtmwZ0tLS0KxZMwwdOhQTJ06Em5ubzmu+/fZb7N69G97e3mjatCkAoFOnTti5cyd+//13NG/eHC1atMCcOXNQo0YNA2wxEcmEEELqIoiIpPTZZ58hIiICt27dkroUIjICjtkhokpn4cKFaN68OZydnfHnn3/i66+/xoQJE6Qui4iMhGGHiCqdq1evYubMmUhNTYWPjw/efvttTJ8+XeqyiMhIeBqLiIiIKjQOUCYiIqIKjWGHiIiIKjSGHSIiIqrQGHaIiIioQmPYISIiogqNYYeIiIgqNIYdIiIiqtAYdoiIiKhCY9ghIiKiCu3/AOaYaiIZ+pVrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AdjacencyWorld(object):\n",
    "    def __init__(self, num_nodes, band_size=10, edge_rate=0.5, random_move_chance=0.5, seed=695):\n",
    "        self.mat = self.get_random_adjacency(band_size=band_size, num_nodes=num_nodes, edge_rate=edge_rate, seed=seed)\n",
    "        self.states = list(range(num_nodes))\n",
    "        self.rewards = -1 * np.ones((num_nodes))\n",
    "        self.goal = num_nodes // 2\n",
    "        self.rewards[self.goal] = 10\n",
    "        self.random_move_chance = random_move_chance\n",
    "\n",
    "    def get_random_adjacency(self, band_size, num_nodes, edge_rate=1.0, seed=695):\n",
    "        random.seed(seed)\n",
    "        mat = np.zeros((num_nodes, num_nodes))\n",
    "        for ii in range(num_nodes):\n",
    "            mat[ii, ii] = 1.0\n",
    "            for jj in range(ii + 1, min(ii + band_size, num_nodes)):\n",
    "                val = 1.0 * (random.random() < edge_rate)\n",
    "                mat[ii, jj] = val\n",
    "                mat[jj, ii] = val\n",
    "        return mat\n",
    "\n",
    "    def plot_adjacency_mat(self):\n",
    "        plt.figure(dpi=150)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.imshow(self.mat, interpolation='none')\n",
    "\n",
    "    def get_actions_for_state(self, state):\n",
    "        return np.where(self.mat[state])[0].tolist()\n",
    "\n",
    "    def get_transition_probs(self, state, action):\n",
    "        actions = self.get_actions_for_state(state)\n",
    "        num_actions = len(actions)\n",
    "        prob_vec = np.zeros_like(self.rewards)\n",
    "        for rand_action in actions:\n",
    "            prob_vec[rand_action] = self.random_move_chance / num_actions\n",
    "\n",
    "        prob_vec[action] += (1 - self.random_move_chance)\n",
    "        return prob_vec\n",
    "\n",
    "    def get_random_state(self):\n",
    "        return random.choice(self.states)\n",
    "\n",
    "    def execute_action(self, state, action):\n",
    "        actions_for_state = self.get_actions_for_state(state)\n",
    "\n",
    "        if action not in actions_for_state:\n",
    "            action = random.choice(actions_for_state)\n",
    "\n",
    "        probs = self.get_transition_probs(state, action)\n",
    "        new_state = np.random.choice(self.states, p=probs)\n",
    "        return self.rewards[new_state], new_state\n",
    "\n",
    "\n",
    "def Q_learning(env, num_iterations, num_steps=30, gamma=0.98, learning_rate=0.005, epsilon=0.1, seed=695):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    Q_s_a = np.zeros((len(env.states), len(env.states)))\n",
    "    total_rewards = []\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        total_reward = 0\n",
    "        state = env.get_random_state()\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            actions = env.get_actions_for_state(state)\n",
    "            if random.random() < epsilon:\n",
    "                action = random.choice(actions)\n",
    "            else:\n",
    "                action = np.argmax(Q_s_a[state, actions])\n",
    "\n",
    "            r, new_state = env.execute_action(state, action)\n",
    "\n",
    "            Q_s_a[state, action] = (1 - learning_rate) * Q_s_a[state, action] + \\\n",
    "                                   learning_rate * (r + gamma * np.max(Q_s_a[new_state]))\n",
    "\n",
    "            total_reward += r\n",
    "            state = new_state\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "\n",
    "    policy = np.zeros(len(env.states))\n",
    "    for state in env.states:\n",
    "        actions = env.get_actions_for_state(state)\n",
    "        action_ind = np.argmax(Q_s_a[state, actions])\n",
    "        policy[state] = actions[action_ind]\n",
    "\n",
    "    return list(policy.astype(int)), total_rewards\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy, num_episodes=100, num_steps=30):\n",
    "    total_rewards = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        total_reward = 0\n",
    "        state = env.get_random_state()\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            action = policy[state]\n",
    "            r, new_state = env.execute_action(state, action)\n",
    "            total_reward += r\n",
    "            state = new_state\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "\n",
    "    return np.mean(total_rewards)\n",
    "\n",
    "\n",
    "def evaluate_learning_rates(env, num_iterations=100, num_steps=30, learning_rates=None):\n",
    "    if learning_rates is None:\n",
    "        learning_rates = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "    avg_rewards = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        policy, total_rewards = Q_learning(env, num_iterations=num_iterations, learning_rate=lr)\n",
    "        avg_reward = evaluate_policy(env, policy)\n",
    "        avg_rewards.append(avg_reward)\n",
    "\n",
    "    return learning_rates, avg_rewards\n",
    "\n",
    "\n",
    "# Create an instance of AdjacencyWorld\n",
    "env = AdjacencyWorld(num_nodes=20, band_size=5, edge_rate=0.3, random_move_chance=0.2, seed=42)\n",
    "\n",
    "# Evaluate different learning rates\n",
    "learning_rates, avg_rewards = evaluate_learning_rates(env)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(learning_rates, avg_rewards, marker='o')\n",
    "plt.title('Average Reward vs Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FuilRQO-HkeH",
   "metadata": {
    "id": "FuilRQO-HkeH"
   },
   "source": [
    "### ***QUESTION (1-3 sentences)*** The rate of convergence for Q learning is significantly slower than that of Value Iteration. What information does Value Iteration have access to (and indeed makes use of) that makes it converge faster?\n",
    "\n",
    "\n",
    "Value iteration has access to all state-action pairs in the environment's transition probabilities and rewards. This makes it possible to determine the best value function for each state. Contrarily, Q-learning can only access the rewards and transition probabilities for the state-action pairs it has already visited. As a result, Q-learning must spend more time figuring out the worth of each state-action pair through trial and error.\n",
    "\n",
    "### ***QUESTION (3-5 sentences)*** When the learning rate is very low, the performance is not particularly good. From looking at the plots of the total reward over time, what is likely the cause? How would you fix this issue (without changing the learning rate)?\n",
    "\n",
    "The Q-values change very slowly when the learning rate is relatively low. As a result, the agent must spend a lot of time learning the importance of each state-action pair. We can use a method called exploration to resolve this problem without altering the learning rate. Exploration is the practice of trying out novel behaviors and emotional states in order to better understand one's surroundings. Using an epsilon-greedy policy is one method to put exploration into practice. A strategy that is epsilon-greedy will take the optimum course of action given the Q-values with probability 1 - epsilon and a random action with probability epsilon.\n",
    "\n",
    "\n",
    "### ***QUESTION (2-4 sentences)**** When the learning is too high, the performance is also not very good. Why does this happen?\n",
    "\n",
    "When the learning rate is too high, the Q-values shift too quickly. As a result, the agent may overfit to the training data and develop a policy that cannot be applied to different settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e357ed",
   "metadata": {
    "id": "38e357ed"
   },
   "source": [
    "## P4.3 Connect Four and MCTS\n",
    "\n",
    "I have provided you with a (pure python) implementation of the popular turn-based game \"Connect Four\". In this game, you 'drop' pieces of different color into the game board, trying to get four in a row (along any axis) before your opponent can. In this question, I have provided you with an implementation of minimax search, which you will use to compare against your own implementation of Monte Carlo Tree Search.\n",
    "\n",
    "### P4.3.1 Minimax\n",
    "\n",
    "I have provided you with an already-complete minimax algorithm implementation. The algorithm has an element of randomness in it: if it multiple actions are of equal value, it picks one at random. The evaluation code below pits two different minimax algorithms against one another: one that runs at depth 5 and one that runs at depth 3.\n",
    "\n",
    "**QUESTION** (2-3 sentences) What is the evaluation function being used to evaluate the goodness of a board state once the maximum depth is reached? How \"useful\" is the value function I have provided?\n",
    "\n",
    "**TASK** Run the evaluation code below and observe the results.\n",
    "\n",
    "**RESULTS** Include the win/draw counts in your writeup.\n",
    "\n",
    "**QUESTION** (1-3 sentences) You may notice that sometimes the depth-3 minimax search wins against the depth-5 minimax search. How is this possible?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df98d0f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "df98d0f7",
    "outputId": "96c9d2c8-79cf-4284-e0f2-eb0a3f3f9490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A board and randomly playing moves.\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "=================\n",
      "[0 1 2 3 4 5 6]\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 1 2 0 0 0]|\n",
      "|[1 2 2 2 1 0 0]|\n",
      "|[1 1 1 2 2 1 0]|\n",
      "|[1 2 1 2 2 1 2]|\n",
      "=================\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Connect Four Implementation\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class ConnectFourBoard(object):\n",
    "    def __init__(self, nrows=6, ncols=7):\n",
    "        self.current_player = 1\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "        self.board = np.zeros((nrows, ncols), int)\n",
    "        self.winner = None\n",
    "\n",
    "    def get_moves(self):\n",
    "        return np.where(self.board[0] == 0)[0]\n",
    "\n",
    "    def _check_winner(self, row, col):\n",
    "        \"\"\"Check if the move in col ended the game.\n",
    "        Not wonderful code, but easy to follow and debug.\"\"\"\n",
    "        b, r, c = self.board, row, col\n",
    "\n",
    "        # Diagonal 1\n",
    "        if r - 3 >= 0 and c - 3 >= 0:\n",
    "            if b[r, c] == b[r-1, c-1] == b[r-2, c-2] == b[r-3, c-3]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if r - 2 >= 0 and c - 2 >= 0 and r + 1 < self.nrows and c + 1 < self.ncols:\n",
    "            if b[r+1, c+1] == b[r, c] == b[r-1, c-1] == b[r-2, c-2]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if r - 1 >= 0 and c - 1 >= 0 and r + 2 < self.nrows and c + 2 < self.ncols:\n",
    "            if b[r+2, c+2] == b[r+1, c+1] == b[r, c] == b[r-1, c-1]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if r + 3 < self.nrows and c + 3 < self.ncols:\n",
    "            if b[r+3, c+3] == b[r+2, c+2] == b[r+1, c+1] == b[r, c]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "\n",
    "        # Diagonal 2\n",
    "        if r - 3 >= 0 and c + 3 < self.ncols:\n",
    "            if b[r, c] == b[r-1, c+1] == b[r-2, c+2] == b[r-3, c+3]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if r - 2 >= 0 and c + 2 < self.ncols and r + 1 < self.nrows and c - 1 >= 0:\n",
    "            if b[r+1, c-1] == b[r, c] == b[r-1, c+1] == b[r-2, c+2]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if r - 1 >= 0 and c + 1 < self.ncols and r + 2 < self.nrows and c - 2 >= 0:\n",
    "            if b[r+2, c-2] == b[r+1, c-1] == b[r, c] == b[r-1, c+1]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if r + 3 < self.nrows and c - 3 >= 0:\n",
    "            if b[r+3, c-3] == b[r+2, c-2] == b[r+1, c-1] == b[r, c]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "\n",
    "        # Flat\n",
    "        if c + 3 < self.ncols:\n",
    "            if b[r, c] == b[r, c+1] == b[r, c+2] == b[r, c+3]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if c + 2 < self.ncols and c - 1 >= 0:\n",
    "            if b[r, c-1] == b[r, c] == b[r, c+1] == b[r, c+2]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if c + 1 < self.ncols and c - 2 >= 0:\n",
    "            if b[r, c-2] == b[r, c-1] == b[r, c] == b[r, c+1]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if c - 3 >= 0:\n",
    "            if b[r, c-3] == b[r, c-2] == b[r, c-1] == b[r, c]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "\n",
    "        # Down\n",
    "        if r - 3 >= 0:\n",
    "            if b[r, c] == b[r-1, c] == b[r-2, c] == b[r-3, c]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "        if r + 3 < self.nrows:\n",
    "            if b[r+3, c] == b[r+2, c] == b[r+1, c] == b[r, c]:\n",
    "                self.winner = b[r, c]\n",
    "                return\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def play_move(self, col):\n",
    "        try:\n",
    "            row = np.where(self.board[:, col] == 0)[0][-1]\n",
    "        except IndexError:\n",
    "            raise ValueError(f\"Cannot play column '{col}'.\")\n",
    "        self.board[row, col] = self.current_player\n",
    "\n",
    "        # Check for a winner\n",
    "        self._check_winner(row, col)\n",
    "\n",
    "        # Check if no more moves\n",
    "        if len(self.get_moves()) == 0:\n",
    "            self.winner = 0\n",
    "\n",
    "        # Switch player\n",
    "        if self.current_player == 1:\n",
    "            self.current_player = 2\n",
    "        else:\n",
    "            self.current_player = 1\n",
    "\n",
    "        return self\n",
    "\n",
    "    def play_random_move(self):\n",
    "        self.play_move(random.choice(self.get_moves()))\n",
    "\n",
    "    def play_random_moves_until_done(self):\n",
    "        while self.winner is None:\n",
    "            self.play_random_move()\n",
    "\n",
    "        return self.winner\n",
    "\n",
    "    def __str__(self):\n",
    "        string = ''\n",
    "        print()\n",
    "        for row in self.board:\n",
    "            string += f\"|{row}|\\n\"\n",
    "        string += '=' * (2 * self.ncols + 3)\n",
    "\n",
    "        return string\n",
    "\n",
    "# Some simple tests\n",
    "print(\"A board and randomly playing moves.\")\n",
    "board = ConnectFourBoard(nrows=6, ncols=7)\n",
    "print(board)\n",
    "print(board.get_moves())\n",
    "\n",
    "while board.winner is None:\n",
    "    board.play_random_move()\n",
    "\n",
    "print(board)\n",
    "print(board.winner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4360e71a",
   "metadata": {
    "id": "4360e71a"
   },
   "outputs": [],
   "source": [
    "# Minimax search\n",
    "def minimax(state, depth, is_max_turn=True, is_start=True, player=None, verbose=False):\n",
    "    if player is None:\n",
    "        player = state.current_player\n",
    "    if depth == 0 or state.winner is not None:\n",
    "        if state.winner is None or state.winner == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2 * (state.winner == player) - 1\n",
    "\n",
    "    moves = state.get_moves()\n",
    "    values = [minimax(state.copy().play_move(move), depth - 1, not is_max_turn,\n",
    "                      is_start=False, player=player)\n",
    "              for move in moves]\n",
    "\n",
    "    if is_start:\n",
    "        best_actions = np.where(np.array(values) == max(values))[0]\n",
    "        action_ind = random.choice(best_actions)\n",
    "        if verbose:\n",
    "            print(list(zip(values, moves)), action_ind)\n",
    "        return moves[action_ind]\n",
    "    if is_max_turn:\n",
    "        return max(values)\n",
    "    else:\n",
    "        return min(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3f6302",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "cd3f6302",
    "outputId": "89167cb9-45ca-487a-8b6e-40c8b3d7115e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|[0 0 0 2 0 0 0]|\n",
      "|[0 1 1 1 1 0 0]|\n",
      "|[2 2 2 1 2 1 0]|\n",
      "|[2 1 1 1 2 2 0]|\n",
      "|[1 2 1 2 2 2 1]|\n",
      "|[2 2 1 2 1 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 1\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 0\n",
      "Draws: 0\n",
      "\n",
      "|[0 2 1 0 2 1 1]|\n",
      "|[0 2 2 0 2 2 2]|\n",
      "|[0 1 1 1 1 1 1]|\n",
      "|[0 1 2 2 2 1 1]|\n",
      "|[2 2 1 1 2 2 1]|\n",
      "|[2 2 2 1 1 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 2\n",
      "Depth 6 Wins: 2\n",
      "Depth 4 Wins: 0\n",
      "Draws: 0\n",
      "\n",
      "|[2 2 2 2 0 2 1]|\n",
      "|[1 1 1 2 0 1 1]|\n",
      "|[2 2 2 1 0 1 1]|\n",
      "|[1 1 2 2 0 2 2]|\n",
      "|[1 2 1 1 0 2 2]|\n",
      "|[2 1 2 1 1 1 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 3\n",
      "Depth 6 Wins: 2\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 2 0 0 0 0 0]|\n",
      "|[0 1 1 0 2 0 0]|\n",
      "|[0 2 1 0 1 2 0]|\n",
      "|[0 2 1 0 2 1 0]|\n",
      "|[2 2 1 1 1 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 4\n",
      "Depth 6 Wins: 3\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[2 2 2 1 1 2 1]|\n",
      "|[1 1 1 2 2 1 1]|\n",
      "|[2 1 2 1 2 2 2]|\n",
      "|[2 1 1 1 2 2 2]|\n",
      "|[1 2 2 2 1 1 1]|\n",
      "|[2 2 1 1 1 2 1]|\n",
      "=================\n",
      "0\n",
      "======\n",
      "Total Plays: 5\n",
      "Depth 6 Wins: 3\n",
      "Depth 4 Wins: 1\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 2 1]|\n",
      "|[0 0 0 0 0 1 2]|\n",
      "|[2 0 1 2 1 1 1]|\n",
      "|[1 2 2 1 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 6\n",
      "Depth 6 Wins: 4\n",
      "Depth 4 Wins: 1\n",
      "Draws: 1\n",
      "\n",
      "|[2 0 0 0 0 2 0]|\n",
      "|[1 1 2 2 1 2 0]|\n",
      "|[1 1 2 1 2 2 0]|\n",
      "|[1 2 1 2 1 1 0]|\n",
      "|[2 2 1 2 1 2 0]|\n",
      "|[1 2 2 1 1 1 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 7\n",
      "Depth 6 Wins: 4\n",
      "Depth 4 Wins: 2\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[1 0 0 0 1 0 0]|\n",
      "|[2 2 2 2 2 0 2]|\n",
      "|[2 1 1 2 1 1 2]|\n",
      "|[1 2 1 2 1 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 8\n",
      "Depth 6 Wins: 4\n",
      "Depth 4 Wins: 3\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 1 0 0 0 0 0]|\n",
      "|[0 2 1 0 1 2 0]|\n",
      "|[0 2 2 0 2 1 1]|\n",
      "|[1 1 2 2 2 1 1]|\n",
      "|[1 2 2 1 1 2 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 9\n",
      "Depth 6 Wins: 4\n",
      "Depth 4 Wins: 4\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 2 2 0 0 0]|\n",
      "|[0 1 1 1 0 0 0]|\n",
      "|[0 2 1 2 1 0 0]|\n",
      "|[2 2 2 1 1 1 2]|\n",
      "|[1 2 2 1 2 2 1]|\n",
      "|[1 1 2 1 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 10\n",
      "Depth 6 Wins: 5\n",
      "Depth 4 Wins: 4\n",
      "Draws: 1\n",
      "\n",
      "|[0 1 0 0 0 0 0]|\n",
      "|[0 2 0 0 0 0 0]|\n",
      "|[0 2 1 1 0 2 0]|\n",
      "|[0 2 1 1 0 1 0]|\n",
      "|[0 1 2 2 1 2 0]|\n",
      "|[2 1 1 2 2 1 0]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 11\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 4\n",
      "Draws: 1\n",
      "\n",
      "|[1 0 0 0 1 0 1]|\n",
      "|[2 2 1 2 2 0 1]|\n",
      "|[2 1 1 1 2 0 2]|\n",
      "|[2 1 2 2 2 2 1]|\n",
      "|[1 2 2 2 1 1 1]|\n",
      "|[1 1 2 2 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 12\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 5\n",
      "Draws: 1\n",
      "\n",
      "|[2 1 1 2 2 1 1]|\n",
      "|[1 1 2 2 1 2 2]|\n",
      "|[1 2 1 1 2 1 1]|\n",
      "|[1 1 2 2 1 2 2]|\n",
      "|[2 2 1 2 1 2 1]|\n",
      "|[1 1 2 2 1 2 2]|\n",
      "=================\n",
      "0\n",
      "======\n",
      "Total Plays: 13\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 5\n",
      "Draws: 2\n",
      "\n",
      "|[0 0 0 1 0 0 0]|\n",
      "|[2 0 0 2 0 0 0]|\n",
      "|[1 2 1 1 0 1 0]|\n",
      "|[2 1 2 1 1 2 1]|\n",
      "|[2 2 2 1 2 2 1]|\n",
      "|[1 1 1 2 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 14\n",
      "Depth 6 Wins: 7\n",
      "Depth 4 Wins: 5\n",
      "Draws: 2\n",
      "\n",
      "|[1 0 0 1 2 0 0]|\n",
      "|[2 0 0 2 2 0 0]|\n",
      "|[1 1 1 1 1 0 0]|\n",
      "|[2 1 1 2 2 0 1]|\n",
      "|[2 1 2 2 1 2 1]|\n",
      "|[2 2 1 2 1 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 15\n",
      "Depth 6 Wins: 8\n",
      "Depth 4 Wins: 5\n",
      "Draws: 2\n",
      "\n",
      "|[1 1 1 2 2 1 2]|\n",
      "|[2 2 1 1 1 2 2]|\n",
      "|[1 1 1 2 2 2 1]|\n",
      "|[2 1 2 1 1 2 2]|\n",
      "|[2 2 1 1 2 1 1]|\n",
      "|[1 2 1 2 2 2 1]|\n",
      "=================\n",
      "0\n",
      "======\n",
      "Total Plays: 16\n",
      "Depth 6 Wins: 8\n",
      "Depth 4 Wins: 5\n",
      "Draws: 3\n",
      "\n",
      "|[2 2 1 2 2 2 0]|\n",
      "|[1 2 1 2 2 1 0]|\n",
      "|[2 1 2 1 1 1 0]|\n",
      "|[2 1 1 2 1 2 0]|\n",
      "|[1 1 1 2 1 2 1]|\n",
      "|[2 2 1 2 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 17\n",
      "Depth 6 Wins: 8\n",
      "Depth 4 Wins: 6\n",
      "Draws: 3\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 1 2 0 0 1]|\n",
      "|[0 0 1 2 0 1 2]|\n",
      "|[2 1 2 2 1 2 1]|\n",
      "|[2 1 2 2 1 1 1]|\n",
      "|[2 2 2 1 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 18\n",
      "Depth 6 Wins: 8\n",
      "Depth 4 Wins: 7\n",
      "Draws: 3\n",
      "\n",
      "|[2 1 0 2 1 0 0]|\n",
      "|[1 2 0 1 2 2 0]|\n",
      "|[2 1 1 1 1 1 2]|\n",
      "|[1 1 2 1 2 2 2]|\n",
      "|[2 1 1 2 2 2 1]|\n",
      "|[1 2 2 1 1 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 19\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 7\n",
      "Draws: 3\n",
      "\n",
      "|[2 0 0 0 0 1 0]|\n",
      "|[1 0 0 2 0 1 0]|\n",
      "|[1 0 0 2 0 2 1]|\n",
      "|[1 0 0 2 0 2 2]|\n",
      "|[2 1 1 2 2 1 1]|\n",
      "|[2 2 2 1 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 20\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 8\n",
      "Draws: 3\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 2 0 0]|\n",
      "|[2 2 1 1 1 1 0]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 21\n",
      "Depth 6 Wins: 10\n",
      "Depth 4 Wins: 8\n",
      "Draws: 3\n",
      "\n",
      "|[1 2 2 1 0 1 2]|\n",
      "|[2 2 1 1 1 2 1]|\n",
      "|[1 1 1 2 2 1 1]|\n",
      "|[2 2 2 1 2 2 1]|\n",
      "|[1 1 2 2 2 1 2]|\n",
      "|[1 2 2 1 1 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 22\n",
      "Depth 6 Wins: 11\n",
      "Depth 4 Wins: 8\n",
      "Draws: 3\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 2 2 0 0 0]|\n",
      "|[1 0 2 1 1 0 0]|\n",
      "|[2 1 1 1 1 2 0]|\n",
      "|[1 2 1 2 2 1 0]|\n",
      "|[2 2 1 1 1 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 23\n",
      "Depth 6 Wins: 12\n",
      "Depth 4 Wins: 8\n",
      "Draws: 3\n",
      "\n",
      "|[0 0 0 0 1 0 0]|\n",
      "|[0 0 0 0 2 0 0]|\n",
      "|[0 2 0 2 1 0 2]|\n",
      "|[2 1 1 1 1 2 1]|\n",
      "|[1 1 2 1 2 2 2]|\n",
      "|[2 1 1 1 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 24\n",
      "Depth 6 Wins: 13\n",
      "Depth 4 Wins: 8\n",
      "Draws: 3\n"
     ]
    }
   ],
   "source": [
    "# minimax evaluation code\n",
    "\n",
    "def print_wins_minimax(wins):\n",
    "    print(\"======\")\n",
    "    print(f\"Total Plays: {len(wins)}\")\n",
    "    print(f\"Depth 6 Wins: {len([w for w in wins if w == 1])}\")\n",
    "    print(f\"Depth 4 Wins: {len([w for w in wins if w == 2])}\")\n",
    "    print(f\"Draws: {len([w for w in wins if w == 0])}\")\n",
    "\n",
    "\n",
    "wins = []\n",
    "for _ in range(25):\n",
    "    board = ConnectFourBoard(nrows=6, ncols=7)\n",
    "    board.current_player = random.choice([1, 2])\n",
    "    while board.winner is None:\n",
    "        if board.current_player == 1:\n",
    "            action = minimax(board, depth=5)\n",
    "        else:\n",
    "            action = minimax(board, depth=3)\n",
    "        board.play_move(action)\n",
    "\n",
    "    print(board)\n",
    "    print(board.winner)\n",
    "    wins.append(board.winner)\n",
    "    print_wins_minimax(wins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C_-m7R-jLdfj",
   "metadata": {
    "id": "C_-m7R-jLdfj"
   },
   "source": [
    "## QUESTION (2-3 sentences) What is the evaluation function being used to evaluate the goodness of a board state once the maximum depth is reached? How \"useful\" is the value function I have provided?\n",
    "\n",
    "### Evaluation Function at Maximum Depth:\n",
    "A basic utility function that allocates values based on the game's winner serves as the \"evaluation function\" used to judge the goodness of a board state at the greatest depth. The value is zero if there is no winner (draw). The value is 1 if the present player triumphs, and -1 if the rival does. This function essentially takes the game's conclusion into account in the final states.\n",
    "\n",
    "Although the supplied evaluation function is simple, it can be lacking in sophistication. It does not take into account the quality of the situation or prospective strategies; it just considers the winner.\n",
    "\n",
    "### Usefulness of the Value Function:\n",
    "The value function offered is straightforward and useful for identifying the game's victor in the terminal states. However, at intermediate stages particularly at the deepest level, the evaluation is restricted to the final result without taking the finer points of the game position into account.\n",
    "\n",
    "Because the function doesn't account for the subtleties of advantageous locations, strategic components, or anticipated future actions, this simplicity may result in less than ideal decisions. To provide a more complex evaluation, a more advanced evaluation function can take into account elements like piece count, positional advantages, and prospective threats.\n",
    "\n",
    "\n",
    "## QUESTION (1-3 sentences) You may notice that sometimes the depth-3 minimax search wins against the depth-5 minimax search. How is this possible?\n",
    "\n",
    "The depth-3 minimax search winning versus the depth-5 minimax search can occur due to the unpredictability included in the decision-making process. When numerous moves have the same evaluation score, the minimax algorithm as it is currently implemented randomly chooses one of the best moves.\n",
    "\n",
    "When there are several equally good movements available for the depth-3 search, the random selection may result in a better move than the depth-5 search, which may be more deterministic in its selection. The randomization introduces variety, and occasionally, the depth-3 search might get lucky and make a move that is more favorable and successful. This demonstrates the significance of the random component in move choice under equal assessments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d07199f",
   "metadata": {
    "id": "2d07199f"
   },
   "source": [
    "### P4.3.2 Monte-Carlo Tree Search\n",
    "\n",
    "*Note: regardless of which algorithm goes first, MCTS is always represented by the number '2' in the printed out board states and minimax is always '1'*\n",
    "\n",
    "**TASK** Complete the functions `monte_carlo_tree_search`, `backpropagate`, `best_child`, and `best_uct`.\n",
    "\n",
    "**CODE** Include your implementations of `monte_carlo_tree_search`, `backpropagate`, `best_child`, and `best_uct` in your writeup.\n",
    "\n",
    "**TASK** Run the evaluation code below. (Note that it may take a few minutes to run all 25 games.)\n",
    "\n",
    "**QUESTION+RESULTS+PLOTS** For the given configuration (1000 iterations, C=5), which algorithm wins more often? Pick a couple final board states (printed out when one strategy wins) and include them in your writeup (screenshots are acceptable).\n",
    "\n",
    "**QUESTION+RESULTS** Rerun the experiments with C=0.1 and C=25. Include the win rates; how well does MCTS perform when you change C?\n",
    "\n",
    "**QUESTION+PLOTS** (4-5 sentences) Describe how the behavior of the MCTS changes when you change the value of C. Pick a couple final board states (printed out when one strategy wins) that support your conclusion and include them in your writeup (screenshots are acceptable). In your answer, you might consider discussing the types of ways MCTS wins/loses for different values of C. Be sure to label which value of C was used for each final board state you include in your writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4fd00a",
   "metadata": {
    "id": "4a4fd00a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Starter Code: MCTS Implementation\n",
    "import time\n",
    "\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self, *, start_state=None, parent=None, move=None):\n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.move = None\n",
    "            self.state = start_state\n",
    "        else:\n",
    "            self.parent = parent\n",
    "            self.move = move\n",
    "            self.state = parent.state.copy()\n",
    "            self.state.play_move(move)\n",
    "\n",
    "        self.values = []\n",
    "        self.n = 0\n",
    "        if self.is_terminal_state:\n",
    "            self.unexplored_moves = set()\n",
    "        else:\n",
    "            self.unexplored_moves = set(self.state.get_moves())\n",
    "        self.children = set([])\n",
    "\n",
    "    @property\n",
    "    def fully_expanded(self):\n",
    "        return len(self.unexplored_moves) == 0\n",
    "\n",
    "    @property\n",
    "    def is_terminal_state(self):\n",
    "        return (self.state.winner is not None)\n",
    "\n",
    "\n",
    "def monte_carlo_tree_search(start_state, num_iterations=1000):\n",
    "    \"\"\"MCTS core loop\"\"\"\n",
    "    root = Tree(start_state=start_state)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return best_child(root)\n",
    "\n",
    "def best_child(node):\n",
    "    \"\"\"When done sampling, pick the child visited the most.\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def best_uct(node, C=5):\n",
    "    \"\"\"Pick the best action according to the UCB/UCT algorithm\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def traverse(node):\n",
    "    while node.fully_expanded and not node.is_terminal_state:\n",
    "        node = best_uct(node)\n",
    "    if node.is_terminal_state:\n",
    "        return node\n",
    "\n",
    "    move = node.unexplored_moves.pop()\n",
    "    new_child = Tree(parent=node, move=move)\n",
    "    node.children.add(new_child)\n",
    "    return new_child\n",
    "\n",
    "\n",
    "def rollout(node, start_state):\n",
    "    winner = node.state.copy().play_random_moves_until_done()\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    elif winner == start_state.current_player:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def backpropagate(node, simulation_result):\n",
    "    \"\"\"Update the node and its parent (via recursion).\"\"\"\n",
    "    if node is None:\n",
    "        return\n",
    "\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5hYcqPSlmXz",
   "metadata": {
    "id": "e5hYcqPSlmXz"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self, *, start_state=None, parent=None, move=None):\n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.move = None\n",
    "            self.state = start_state\n",
    "        else:\n",
    "            self.parent = parent\n",
    "            self.move = move\n",
    "            self.state = parent.state.copy()\n",
    "            self.state.play_move(move)\n",
    "\n",
    "        self.values = []\n",
    "        self.n = 0\n",
    "        if self.is_terminal_state:\n",
    "            self.unexplored_moves = set()\n",
    "        else:\n",
    "            self.unexplored_moves = set(self.state.get_moves())\n",
    "        self.children = set([])\n",
    "\n",
    "    @property\n",
    "    def fully_expanded(self):\n",
    "        return len(self.unexplored_moves) == 0\n",
    "\n",
    "    @property\n",
    "    def is_terminal_state(self):\n",
    "        return (self.state.winner is not None)\n",
    "\n",
    "\n",
    "def monte_carlo_tree_search(start_state, num_iterations=1000):\n",
    "    root = Tree(start_state=start_state)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        node = traverse(root)\n",
    "        simulation_result = rollout(node, start_state)\n",
    "        backpropagate(node, simulation_result)\n",
    "\n",
    "    return best_child(root).move\n",
    "\n",
    "\n",
    "def best_child(node):\n",
    "    return max(node.children, key=lambda child: child.n)\n",
    "\n",
    "\n",
    "def best_uct(node, C=5):\n",
    "    total_visits = sum(child.n for child in node.children) + 1\n",
    "    best_child = max(node.children, key=lambda child: child.n / (child.n + C * math.sqrt(math.log(total_visits) / (child.n + 1))))\n",
    "    return best_child\n",
    "\n",
    "\n",
    "def traverse(node):\n",
    "    while node.fully_expanded and not node.is_terminal_state:\n",
    "        node = best_uct(node)\n",
    "    if node.is_terminal_state:\n",
    "        return node\n",
    "    move = node.unexplored_moves.pop()\n",
    "    new_child = Tree(parent=node, move=move)\n",
    "    node.children.add(new_child)\n",
    "    return new_child\n",
    "\n",
    "\n",
    "def rollout(node, start_state):\n",
    "    winner = node.state.copy().play_random_moves_until_done()\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    elif winner == start_state.current_player:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def backpropagate(node, simulation_result):\n",
    "    if node is None:\n",
    "        return\n",
    "    node.n += 1\n",
    "    node.values.append(simulation_result)\n",
    "    backpropagate(node.parent, simulation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80Ige3thZBkD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "80Ige3thZBkD",
    "outputId": "6a06eee0-44c3-4d39-9d37-d60fe695224f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|[1 1 1 2 0 1 2]|\n",
      "|[2 2 2 1 0 1 2]|\n",
      "|[1 1 2 1 1 1 2]|\n",
      "|[2 2 2 1 2 2 1]|\n",
      "|[1 1 1 2 1 2 2]|\n",
      "|[1 2 1 2 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 1\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 0\n",
      "Draws: 0\n",
      "\n",
      "|[0 1 0 0 0 0 0]|\n",
      "|[2 2 0 0 1 0 0]|\n",
      "|[2 1 0 0 1 1 0]|\n",
      "|[1 2 2 2 2 1 2]|\n",
      "|[1 1 1 2 2 2 1]|\n",
      "|[2 2 2 1 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 2\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 2 1 2 0 1 2]|\n",
      "|[0 1 1 1 0 2 1]|\n",
      "|[2 2 2 2 0 2 2]|\n",
      "|[1 2 1 2 0 1 1]|\n",
      "|[1 1 2 2 2 1 2]|\n",
      "|[2 1 1 1 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 3\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 2\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 1 1 0 0 0]|\n",
      "|[0 0 1 2 0 0 0]|\n",
      "|[0 0 2 2 0 0 1]|\n",
      "|[2 0 1 1 0 0 2]|\n",
      "|[2 2 2 2 0 0 2]|\n",
      "|[1 2 1 2 1 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 4\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 2 0 0 2 0]|\n",
      "|[2 1 1 1 1 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 5\n",
      "Depth 6 Wins: 2\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 1 2 0 2 0 0]|\n",
      "|[1 2 2 0 1 0 0]|\n",
      "|[2 1 2 2 2 0 0]|\n",
      "|[1 2 1 1 1 1 0]|\n",
      "|[1 2 2 2 1 1 1]|\n",
      "|[2 2 2 1 2 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 6\n",
      "Depth 6 Wins: 3\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[2 2 1 1 2 1 1]|\n",
      "|[1 2 2 1 1 2 2]|\n",
      "|[2 1 2 1 2 2 1]|\n",
      "|[1 1 2 2 1 1 1]|\n",
      "|[2 2 1 2 1 2 2]|\n",
      "|[1 1 1 2 2 1 2]|\n",
      "=================\n",
      "0\n",
      "======\n",
      "Total Plays: 7\n",
      "Depth 6 Wins: 3\n",
      "Depth 4 Wins: 3\n",
      "Draws: 1\n",
      "\n",
      "|[1 0 0 0 2 0 0]|\n",
      "|[1 2 0 0 2 2 0]|\n",
      "|[2 1 1 1 1 1 0]|\n",
      "|[2 2 2 1 2 2 0]|\n",
      "|[2 1 1 1 2 1 1]|\n",
      "|[1 2 1 2 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 8\n",
      "Depth 6 Wins: 4\n",
      "Depth 4 Wins: 3\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 2 0 0 1]|\n",
      "|[0 0 0 1 1 0 2]|\n",
      "|[0 0 0 1 1 0 1]|\n",
      "|[2 0 2 2 1 0 2]|\n",
      "|[1 1 2 2 1 2 1]|\n",
      "|[2 1 1 2 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 9\n",
      "Depth 6 Wins: 5\n",
      "Depth 4 Wins: 3\n",
      "Draws: 1\n",
      "\n",
      "|[2 2 1 0 2 2 1]|\n",
      "|[1 1 1 0 2 2 2]|\n",
      "|[1 1 1 0 1 1 2]|\n",
      "|[1 2 2 2 2 1 1]|\n",
      "|[2 1 2 2 2 1 1]|\n",
      "|[1 2 2 2 1 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 10\n",
      "Depth 6 Wins: 5\n",
      "Depth 4 Wins: 4\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 2 2 1 0 1]|\n",
      "|[0 1 2 1 2 1 2]|\n",
      "|[0 2 2 1 2 1 2]|\n",
      "|[2 2 1 1 1 2 2]|\n",
      "|[1 1 2 2 1 1 1]|\n",
      "|[2 1 1 1 2 2 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 11\n",
      "Depth 6 Wins: 5\n",
      "Depth 4 Wins: 5\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 2 1 1 0]|\n",
      "|[0 0 0 1 2 1 2]|\n",
      "|[0 0 1 1 2 2 2]|\n",
      "|[0 1 1 2 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 12\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 5\n",
      "Draws: 1\n",
      "\n",
      "|[2 1 1 2 2 0 1]|\n",
      "|[1 2 2 2 1 0 2]|\n",
      "|[2 2 2 1 2 0 1]|\n",
      "|[1 1 1 2 1 1 1]|\n",
      "|[2 2 1 2 1 2 1]|\n",
      "|[1 2 1 2 2 1 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 13\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[2 1 1 2 1 0 1]|\n",
      "|[1 2 2 1 1 0 1]|\n",
      "|[2 1 1 2 2 2 1]|\n",
      "|[2 2 2 1 2 1 2]|\n",
      "|[2 1 2 2 2 1 2]|\n",
      "|[1 1 2 1 1 1 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 14\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 7\n",
      "Draws: 1\n",
      "\n",
      "|[0 2 0 0 0 0 0]|\n",
      "|[0 1 0 2 1 0 0]|\n",
      "|[0 1 0 2 2 1 1]|\n",
      "|[0 2 0 1 1 1 2]|\n",
      "|[0 2 0 2 1 1 1]|\n",
      "|[2 2 1 1 2 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 15\n",
      "Depth 6 Wins: 7\n",
      "Depth 4 Wins: 7\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 2 0 0 0]|\n",
      "|[0 0 0 2 0 0 0]|\n",
      "|[1 1 1 2 0 0 0]|\n",
      "|[2 1 1 2 0 0 2]|\n",
      "|[1 2 2 1 1 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 16\n",
      "Depth 6 Wins: 7\n",
      "Depth 4 Wins: 8\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 1 0 0 0]|\n",
      "|[0 0 0 1 1 1 0]|\n",
      "|[0 0 0 2 2 1 1]|\n",
      "|[0 1 0 2 2 2 1]|\n",
      "|[0 2 0 1 1 2 2]|\n",
      "|[2 2 2 1 1 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 17\n",
      "Depth 6 Wins: 8\n",
      "Depth 4 Wins: 8\n",
      "Draws: 1\n",
      "\n",
      "|[0 1 0 0 0 0 1]|\n",
      "|[0 2 0 2 0 0 2]|\n",
      "|[0 1 0 2 0 0 1]|\n",
      "|[0 1 2 1 0 0 2]|\n",
      "|[0 1 2 1 2 0 2]|\n",
      "|[2 2 1 1 1 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 18\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 8\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 2 0 1]|\n",
      "|[0 0 0 1 1 2 2]|\n",
      "|[0 0 2 2 2 1 1]|\n",
      "|[0 0 1 2 2 2 1]|\n",
      "|[0 1 2 1 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 19\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 9\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 1 0 0 0 0 0]|\n",
      "|[2 1 1 0 0 0 0]|\n",
      "|[1 2 2 1 2 0 0]|\n",
      "|[2 1 2 2 1 0 0]|\n",
      "|[2 2 1 1 2 0 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 20\n",
      "Depth 6 Wins: 10\n",
      "Depth 4 Wins: 9\n",
      "Draws: 1\n",
      "\n",
      "|[2 0 0 0 0 0 0]|\n",
      "|[1 0 0 0 0 0 0]|\n",
      "|[1 0 0 1 1 0 0]|\n",
      "|[1 0 0 2 1 0 2]|\n",
      "|[2 0 0 2 1 2 2]|\n",
      "|[1 2 0 2 1 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 21\n",
      "Depth 6 Wins: 11\n",
      "Depth 4 Wins: 9\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 2 0]|\n",
      "|[0 1 0 2 0 2 0]|\n",
      "|[2 1 0 1 2 2 0]|\n",
      "|[1 2 1 1 1 1 0]|\n",
      "|[2 1 2 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 22\n",
      "Depth 6 Wins: 12\n",
      "Depth 4 Wins: 9\n",
      "Draws: 1\n",
      "\n",
      "|[2 0 1 1 2 2 2]|\n",
      "|[1 0 2 2 1 1 1]|\n",
      "|[1 0 1 1 1 2 2]|\n",
      "|[2 1 2 2 2 1 1]|\n",
      "|[2 2 1 1 2 1 2]|\n",
      "|[2 1 1 1 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 23\n",
      "Depth 6 Wins: 13\n",
      "Depth 4 Wins: 9\n",
      "Draws: 1\n",
      "\n",
      "|[2 0 0 0 0 0 0]|\n",
      "|[1 0 0 0 0 0 2]|\n",
      "|[2 0 0 1 0 0 1]|\n",
      "|[1 0 0 2 0 1 2]|\n",
      "|[2 2 1 1 1 2 2]|\n",
      "|[2 1 1 1 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 24\n",
      "Depth 6 Wins: 14\n",
      "Depth 4 Wins: 9\n",
      "Draws: 1\n",
      "\n",
      "|[2 2 1 2 0 1 2]|\n",
      "|[2 2 1 1 0 1 1]|\n",
      "|[1 1 2 1 1 1 1]|\n",
      "|[1 2 1 1 2 2 2]|\n",
      "|[2 2 1 2 1 1 2]|\n",
      "|[1 2 2 1 2 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 25\n",
      "Depth 6 Wins: 15\n",
      "Depth 4 Wins: 9\n",
      "Draws: 1\n"
     ]
    }
   ],
   "source": [
    "## c = 5\n",
    "\n",
    "default_move = 0\n",
    "\n",
    "def monte_carlo_tree_search(start_state, num_iterations=1000, C=5):\n",
    "    \"\"\"MCTS core loop\"\"\"\n",
    "    root = Tree(start_state=start_state)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        node = traverse(root)\n",
    "        result = rollout(node, start_state)\n",
    "        backpropagate(node, result)\n",
    "\n",
    "    best_child_node = best_child(root)\n",
    "    if best_child_node is not None:\n",
    "        return best_child_node.move\n",
    "    else:\n",
    "        return default_move\n",
    "\n",
    "\n",
    "\n",
    "def best_child(node):\n",
    "    \"\"\"When done sampling, pick the child visited the most.\"\"\"\n",
    "    if not node.children:\n",
    "        return None\n",
    "    return max(node.children, key=lambda x: x.n)\n",
    "\n",
    "def best_uct(node, C=5):\n",
    "    \"\"\"Pick the best action according to the UCB/UCT algorithm\"\"\"\n",
    "    if node.n == 0:\n",
    "        return random.choice(list(node.unexplored_moves))\n",
    "\n",
    "    exploration_term = C * np.sqrt(np.log(node.n) / (node.n + 1))\n",
    "\n",
    "    def uct_value(child):\n",
    "        if child.n == 0:\n",
    "            return float('inf')\n",
    "        return (sum(child.values) / child.n) + exploration_term / np.sqrt(child.n)\n",
    "\n",
    "    if not node.children:\n",
    "        return random.choice(list(node.unexplored_moves))\n",
    "\n",
    "    return max(node.children, key=uct_value).move\n",
    "\n",
    "\n",
    "def traverse(node):\n",
    "    while hasattr(node, 'is_terminal_state') and hasattr(node, 'fully_expanded') and not node.is_terminal_state and not node.fully_expanded:\n",
    "        node = best_uct(node)\n",
    "\n",
    "    if hasattr(node, 'is_terminal_state') and node.is_terminal_state:\n",
    "        return node\n",
    "\n",
    "\n",
    "    if hasattr(node, 'fully_expanded') and node.fully_expanded:\n",
    "        move = best_uct(node).move\n",
    "    elif hasattr(node, 'unexplored_moves'):\n",
    "        move = node.unexplored_moves.pop()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    new_child = Tree(parent=node, move=move)\n",
    "    node.children.add(new_child)\n",
    "    return new_child\n",
    "\n",
    "def rollout(node, start_state):\n",
    "    if node is None or node.state is None:\n",
    "        return 0\n",
    "\n",
    "    winner = node.state.copy().play_random_moves_until_done()\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    elif winner == start_state.current_player:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "\n",
    "def backpropagate(node, simulation_result):\n",
    "    if node is None:\n",
    "        return\n",
    "    node.values.append(simulation_result)\n",
    "    node.n += 1\n",
    "    backpropagate(node.parent, -simulation_result)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation code\n",
    "def print_wins_mcts(wins):\n",
    "    print(\"======\")\n",
    "    print(f\"Total Plays: {len(wins)}\")\n",
    "    print(f\"MCTS Wins: {len([w for w in wins if w == 2])}\")\n",
    "    print(f\"Minimax Wins: {len([w for w in wins if w == 1])}\")\n",
    "    print(f\"Draws: {len([w for w in wins if w == 0])}\")\n",
    "\n",
    "\n",
    "wins = []\n",
    "for _ in range(25):\n",
    "    board = ConnectFourBoard(nrows=6, ncols=7)\n",
    "    board.current_player = random.choice([1, 2])\n",
    "    while board.winner is None:\n",
    "        if board.current_player == 1:\n",
    "            action = minimax(board, depth=5)\n",
    "        else:\n",
    "            action = minimax(board, depth=3)\n",
    "        board.play_move(action)\n",
    "\n",
    "    print(board)\n",
    "    print(board.winner)\n",
    "    wins.append(board.winner)\n",
    "    print_wins_minimax(wins)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9hOxPAfvsf2o",
   "metadata": {
    "id": "9hOxPAfvsf2o"
   },
   "source": [
    "## c = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "t4PZXseYrdAN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4PZXseYrdAN",
    "outputId": "30bdfe18-dd5b-4e76-fad6-4db3bf3f6e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 2 0 0 0 0 0]|\n",
      "|[0 2 2 0 1 0 0]|\n",
      "|[0 1 1 2 1 1 0]|\n",
      "|[0 2 1 1 1 2 0]|\n",
      "|[2 2 1 2 1 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 1\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 0\n",
      "Draws: 0\n",
      "\n",
      "|[0 1 0 1 1 2 1]|\n",
      "|[0 2 0 1 2 2 2]|\n",
      "|[2 1 0 2 1 1 2]|\n",
      "|[1 2 2 2 2 2 1]|\n",
      "|[1 2 1 2 1 1 2]|\n",
      "|[1 2 2 1 2 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 2\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 2 2 0 0 0]|\n",
      "|[0 1 1 2 2 0 0]|\n",
      "|[0 2 1 1 1 1 0]|\n",
      "|[0 2 1 2 1 2 1]|\n",
      "|[1 1 2 2 1 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 3\n",
      "Depth 6 Wins: 2\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 2 0 1 0]|\n",
      "|[2 0 2 1 0 2 0]|\n",
      "|[2 0 1 2 1 2 0]|\n",
      "|[1 0 2 1 1 1 2]|\n",
      "|[1 1 1 2 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 4\n",
      "Depth 6 Wins: 3\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[2 0 0 0 0 0 0]|\n",
      "|[1 2 2 0 0 0 0]|\n",
      "|[2 1 1 0 1 0 0]|\n",
      "|[1 1 1 0 2 0 0]|\n",
      "|[1 1 2 1 2 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 5\n",
      "Depth 6 Wins: 4\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 2 0 0 0 0]|\n",
      "|[0 2 1 1 1 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 6\n",
      "Depth 6 Wins: 5\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 2 0 0]|\n",
      "|[0 0 0 0 2 0 0]|\n",
      "|[0 1 1 2 2 0 0]|\n",
      "|[0 2 1 1 1 0 2]|\n",
      "|[2 1 2 2 1 1 1]|\n",
      "|[1 2 2 2 1 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 7\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 2 0 0]|\n",
      "|[0 0 2 2 2 0 0]|\n",
      "|[0 0 1 1 1 1 0]|\n",
      "|[0 1 1 1 2 2 0]|\n",
      "|[0 1 2 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 8\n",
      "Depth 6 Wins: 7\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 1 0 0 0 0]|\n",
      "|[0 2 2 1 0 0 2]|\n",
      "|[2 2 1 1 1 0 2]|\n",
      "|[1 1 1 2 2 1 1]|\n",
      "|[2 2 1 1 1 2 1]|\n",
      "|[2 2 2 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 9\n",
      "Depth 6 Wins: 8\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[1 2 2 1 2 0 2]|\n",
      "|[2 2 1 1 1 0 2]|\n",
      "|[2 1 2 2 2 0 1]|\n",
      "|[2 1 1 1 2 1 1]|\n",
      "|[1 1 2 2 1 1 2]|\n",
      "|[1 2 1 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 10\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 1 1 0 2]|\n",
      "|[0 0 0 2 1 1 1]|\n",
      "|[2 2 2 2 1 2 1]|\n",
      "|[1 1 2 1 2 1 2]|\n",
      "|[1 1 2 2 2 1 2]|\n",
      "|[2 2 1 2 1 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 11\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 2\n",
      "Draws: 0\n",
      "\n",
      "|[2 0 1 1 1 2 1]|\n",
      "|[2 0 1 2 2 1 2]|\n",
      "|[1 1 1 1 1 2 1]|\n",
      "|[1 2 2 2 1 1 2]|\n",
      "|[1 2 1 1 2 2 2]|\n",
      "|[2 2 1 2 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 12\n",
      "Depth 6 Wins: 10\n",
      "Depth 4 Wins: 2\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 1 0 0 0 0 0]|\n",
      "|[0 2 0 0 0 0 2]|\n",
      "|[0 1 0 0 1 2 2]|\n",
      "|[0 1 1 1 2 2 1]|\n",
      "|[0 2 1 2 2 1 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 13\n",
      "Depth 6 Wins: 10\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 1 2 2 2 0 2]|\n",
      "|[2 1 1 1 2 0 2]|\n",
      "|[1 2 2 1 1 0 1]|\n",
      "|[1 1 1 2 2 1 1]|\n",
      "|[1 2 2 2 1 1 1]|\n",
      "|[2 1 2 1 2 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 14\n",
      "Depth 6 Wins: 11\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[2 1 0 0 0 0 0]|\n",
      "|[1 1 1 0 0 0 0]|\n",
      "|[1 2 2 1 2 0 0]|\n",
      "|[2 2 1 2 1 0 0]|\n",
      "|[2 2 1 1 2 2 2]|\n",
      "|[2 1 1 1 2 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 15\n",
      "Depth 6 Wins: 12\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[2 0 0 0 0 0 0]|\n",
      "|[2 1 1 1 1 2 0]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 16\n",
      "Depth 6 Wins: 13\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[2 1 0 1 2 2 0]|\n",
      "|[1 1 0 1 1 1 0]|\n",
      "|[2 2 0 1 1 1 2]|\n",
      "|[1 2 0 1 2 2 1]|\n",
      "|[1 2 0 2 2 1 2]|\n",
      "|[2 1 2 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 17\n",
      "Depth 6 Wins: 14\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 2 2 0 0]|\n",
      "|[0 0 0 1 1 0 0]|\n",
      "|[0 0 1 2 2 0 0]|\n",
      "|[0 0 1 1 1 1 1]|\n",
      "|[2 2 2 1 2 1 2]|\n",
      "|[2 1 1 2 1 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 18\n",
      "Depth 6 Wins: 15\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[1 0 0 2 0 2 2]|\n",
      "|[2 0 0 1 1 2 1]|\n",
      "|[2 1 0 1 2 1 2]|\n",
      "|[2 1 1 1 2 2 1]|\n",
      "|[1 1 2 2 1 1 2]|\n",
      "|[2 2 1 2 2 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 19\n",
      "Depth 6 Wins: 16\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 2]|\n",
      "|[0 1 0 0 0 0 1]|\n",
      "|[1 1 1 0 0 2 2]|\n",
      "|[1 2 2 2 2 1 2]|\n",
      "|[2 2 2 1 1 1 2]|\n",
      "|[1 2 1 1 2 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 20\n",
      "Depth 6 Wins: 16\n",
      "Depth 4 Wins: 4\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 2 0 0 0]|\n",
      "|[0 0 0 2 0 0 0]|\n",
      "|[0 0 0 2 0 0 0]|\n",
      "|[2 0 0 1 2 0 0]|\n",
      "|[1 0 2 1 1 1 1]|\n",
      "|[2 1 1 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 21\n",
      "Depth 6 Wins: 17\n",
      "Depth 4 Wins: 4\n",
      "Draws: 0\n",
      "\n",
      "|[2 0 1 0 1 0 0]|\n",
      "|[1 0 1 0 1 0 0]|\n",
      "|[2 0 2 0 1 0 0]|\n",
      "|[1 2 2 2 2 0 1]|\n",
      "|[1 1 1 2 2 0 2]|\n",
      "|[1 2 1 2 2 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 22\n",
      "Depth 6 Wins: 17\n",
      "Depth 4 Wins: 5\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 1 0 0]|\n",
      "|[2 0 0 2 2 1 0]|\n",
      "|[1 1 1 1 2 2 2]|\n",
      "|[2 1 1 1 2 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 23\n",
      "Depth 6 Wins: 18\n",
      "Depth 4 Wins: 5\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 2 0]|\n",
      "|[0 0 1 0 0 1 0]|\n",
      "|[0 0 2 1 2 1 0]|\n",
      "|[0 0 2 1 1 2 0]|\n",
      "|[0 0 1 2 1 1 0]|\n",
      "|[2 0 2 1 1 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 24\n",
      "Depth 6 Wins: 19\n",
      "Depth 4 Wins: 5\n",
      "Draws: 0\n",
      "\n",
      "|[1 1 2 1 1 2 2]|\n",
      "|[2 2 1 2 2 2 1]|\n",
      "|[1 2 2 1 1 1 2]|\n",
      "|[2 1 1 1 2 2 1]|\n",
      "|[1 1 1 2 1 2 1]|\n",
      "|[2 2 1 2 2 1 2]|\n",
      "=================\n",
      "0\n",
      "======\n",
      "Total Plays: 25\n",
      "Depth 6 Wins: 19\n",
      "Depth 4 Wins: 5\n",
      "Draws: 1\n"
     ]
    }
   ],
   "source": [
    "default_move = 0\n",
    "\n",
    "def monte_carlo_tree_search(start_state, num_iterations=1000, C=0.1):\n",
    "    \"\"\"MCTS core loop\"\"\"\n",
    "    root = Tree(start_state=start_state)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        node = traverse(root)\n",
    "        result = rollout(node, start_state)\n",
    "        backpropagate(node, result)\n",
    "\n",
    "    best_child_node = best_child(root)\n",
    "    if best_child_node is not None:\n",
    "        return best_child_node.move\n",
    "    else:\n",
    "        return default_move\n",
    "\n",
    "\n",
    "\n",
    "def best_child(node):\n",
    "    \"\"\"When done sampling, pick the child visited the most.\"\"\"\n",
    "    if not node.children:\n",
    "        return None\n",
    "    return max(node.children, key=lambda x: x.n)\n",
    "\n",
    "def best_uct(node, C=5):\n",
    "    \"\"\"Pick the best action according to the UCB/UCT algorithm\"\"\"\n",
    "    if node.n == 0:\n",
    "        return random.choice(list(node.unexplored_moves))\n",
    "\n",
    "    exploration_term = C * np.sqrt(np.log(node.n) / (node.n + 1))\n",
    "\n",
    "    def uct_value(child):\n",
    "        if child.n == 0:\n",
    "            return float('inf')\n",
    "        return (sum(child.values) / child.n) + exploration_term / np.sqrt(child.n)\n",
    "\n",
    "    if not node.children:\n",
    "        return random.choice(list(node.unexplored_moves))\n",
    "\n",
    "    return max(node.children, key=uct_value).move\n",
    "\n",
    "\n",
    "def traverse(node):\n",
    "    while hasattr(node, 'is_terminal_state') and hasattr(node, 'fully_expanded') and not node.is_terminal_state and not node.fully_expanded:\n",
    "        node = best_uct(node)\n",
    "\n",
    "    if hasattr(node, 'is_terminal_state') and node.is_terminal_state:\n",
    "        return node\n",
    "    if hasattr(node, 'fully_expanded') and node.fully_expanded:\n",
    "        move = best_uct(node).move\n",
    "    elif hasattr(node, 'unexplored_moves'):\n",
    "        move = node.unexplored_moves.pop()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    new_child = Tree(parent=node, move=move)\n",
    "    node.children.add(new_child)\n",
    "    return new_child\n",
    "\n",
    "def rollout(node, start_state):\n",
    "    if node is None or node.state is None:\n",
    "\n",
    "        return 0\n",
    "\n",
    "    winner = node.state.copy().play_random_moves_until_done()\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    elif winner == start_state.current_player:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "\n",
    "def backpropagate(node, simulation_result):\n",
    "    if node is None:\n",
    "        return\n",
    "    node.values.append(simulation_result)\n",
    "    node.n += 1\n",
    "    backpropagate(node.parent, -simulation_result)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation code\n",
    "def print_wins_mcts(wins):\n",
    "    print(\"======\")\n",
    "    print(f\"Total Plays: {len(wins)}\")\n",
    "    print(f\"MCTS Wins: {len([w for w in wins if w == 2])}\")\n",
    "    print(f\"Minimax Wins: {len([w for w in wins if w == 1])}\")\n",
    "    print(f\"Draws: {len([w for w in wins if w == 0])}\")\n",
    "\n",
    "\n",
    "wins = []\n",
    "for _ in range(25):\n",
    "    board = ConnectFourBoard(nrows=6, ncols=7)\n",
    "    board.current_player = random.choice([1, 2])\n",
    "    while board.winner is None:\n",
    "        if board.current_player == 1:\n",
    "            action = minimax(board, depth=5)\n",
    "        else:\n",
    "            action = minimax(board, depth=3)\n",
    "        board.play_move(action)\n",
    "\n",
    "    print(board)\n",
    "    print(board.winner)\n",
    "    wins.append(board.winner)\n",
    "    print_wins_minimax(wins)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DGdroQGYsadD",
   "metadata": {
    "id": "DGdroQGYsadD"
   },
   "source": [
    "## c = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "L6c_mkoEsT4H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6c_mkoEsT4H",
    "outputId": "52939985-4844-4ef9-e13e-55630222137e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|[0 1 1 0 0 0 1]|\n",
      "|[2 2 2 2 0 0 2]|\n",
      "|[1 1 2 1 0 1 1]|\n",
      "|[2 2 1 2 0 1 1]|\n",
      "|[1 2 2 2 0 2 1]|\n",
      "|[2 1 1 2 0 1 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 1\n",
      "Depth 6 Wins: 0\n",
      "Depth 4 Wins: 1\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 1 0 0 2 0]|\n",
      "|[0 2 2 1 0 2 0]|\n",
      "|[0 2 2 2 0 1 2]|\n",
      "|[0 1 1 2 0 1 1]|\n",
      "|[2 1 1 1 2 2 2]|\n",
      "|[1 1 2 2 1 1 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 2\n",
      "Depth 6 Wins: 0\n",
      "Depth 4 Wins: 2\n",
      "Draws: 0\n",
      "\n",
      "|[1 1 1 0 2 1 2]|\n",
      "|[1 2 2 0 2 2 2]|\n",
      "|[2 1 1 0 1 1 1]|\n",
      "|[1 1 1 0 2 2 2]|\n",
      "|[1 2 2 1 2 2 2]|\n",
      "|[1 2 1 2 1 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 3\n",
      "Depth 6 Wins: 1\n",
      "Depth 4 Wins: 2\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 1 0 0 0 1]|\n",
      "|[0 0 2 0 0 2 2]|\n",
      "|[0 0 2 2 0 1 2]|\n",
      "|[0 1 1 1 1 2 1]|\n",
      "|[0 2 1 2 2 1 1]|\n",
      "|[1 2 2 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 4\n",
      "Depth 6 Wins: 2\n",
      "Depth 4 Wins: 2\n",
      "Draws: 0\n",
      "\n",
      "|[1 0 0 0 0 2 1]|\n",
      "|[1 0 0 0 0 1 1]|\n",
      "|[1 2 2 2 2 1 2]|\n",
      "|[2 2 2 1 1 2 1]|\n",
      "|[2 2 1 2 1 2 2]|\n",
      "|[1 1 2 1 1 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 5\n",
      "Depth 6 Wins: 2\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 2 2 0 2 1]|\n",
      "|[0 0 1 1 2 1 2]|\n",
      "|[0 0 2 1 1 1 2]|\n",
      "|[0 1 2 1 2 2 1]|\n",
      "|[0 1 2 2 1 1 2]|\n",
      "|[2 1 1 2 1 1 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 6\n",
      "Depth 6 Wins: 3\n",
      "Depth 4 Wins: 3\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[1 0 0 0 1 0 0]|\n",
      "|[1 1 0 0 2 0 0]|\n",
      "|[2 2 0 0 1 0 1]|\n",
      "|[2 2 2 2 2 1 2]|\n",
      "|[2 1 1 1 2 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 7\n",
      "Depth 6 Wins: 3\n",
      "Depth 4 Wins: 4\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 1 1 0 0]|\n",
      "|[0 0 0 2 1 0 0]|\n",
      "|[0 0 0 1 1 0 0]|\n",
      "|[2 2 0 2 1 0 2]|\n",
      "|[1 1 2 2 2 0 2]|\n",
      "|[2 1 1 1 2 0 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 8\n",
      "Depth 6 Wins: 4\n",
      "Depth 4 Wins: 4\n",
      "Draws: 0\n",
      "\n",
      "|[2 0 0 0 0 0 0]|\n",
      "|[1 2 0 0 0 0 0]|\n",
      "|[1 1 0 0 0 0 0]|\n",
      "|[1 2 1 0 0 2 0]|\n",
      "|[2 1 2 1 2 1 2]|\n",
      "|[1 1 2 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 9\n",
      "Depth 6 Wins: 5\n",
      "Depth 4 Wins: 4\n",
      "Draws: 0\n",
      "\n",
      "|[0 0 0 1 0 2 0]|\n",
      "|[0 0 0 2 0 1 0]|\n",
      "|[0 2 2 2 0 1 0]|\n",
      "|[2 1 1 1 1 1 0]|\n",
      "|[2 2 2 1 1 2 0]|\n",
      "|[1 2 2 2 1 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 10\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 4\n",
      "Draws: 0\n",
      "\n",
      "|[1 1 2 1 1 2 2]|\n",
      "|[2 1 1 2 2 1 1]|\n",
      "|[1 2 2 1 1 1 2]|\n",
      "|[2 2 1 2 2 2 1]|\n",
      "|[1 2 2 2 1 1 2]|\n",
      "|[2 1 2 2 1 1 1]|\n",
      "=================\n",
      "0\n",
      "======\n",
      "Total Plays: 11\n",
      "Depth 6 Wins: 6\n",
      "Depth 4 Wins: 4\n",
      "Draws: 1\n",
      "\n",
      "|[1 2 2 1 0 0 2]|\n",
      "|[1 1 1 2 0 1 2]|\n",
      "|[1 2 1 1 0 2 1]|\n",
      "|[2 2 1 2 1 1 2]|\n",
      "|[1 1 2 2 2 1 2]|\n",
      "|[2 1 2 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 12\n",
      "Depth 6 Wins: 7\n",
      "Depth 4 Wins: 4\n",
      "Draws: 1\n",
      "\n",
      "|[1 0 0 1 1 1 2]|\n",
      "|[2 0 0 2 1 2 1]|\n",
      "|[2 0 0 1 1 2 2]|\n",
      "|[1 0 2 2 2 2 1]|\n",
      "|[2 0 1 2 1 1 1]|\n",
      "|[1 2 1 2 2 2 1]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 13\n",
      "Depth 6 Wins: 7\n",
      "Depth 4 Wins: 5\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 1 2 2 0]|\n",
      "|[1 1 2 1 2 2 0]|\n",
      "|[2 2 2 1 1 1 0]|\n",
      "|[1 2 1 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 14\n",
      "Depth 6 Wins: 8\n",
      "Depth 4 Wins: 5\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 2 0]|\n",
      "|[0 0 1 1 0 2 2]|\n",
      "|[1 0 1 1 0 1 1]|\n",
      "|[2 0 2 1 1 2 1]|\n",
      "|[1 2 2 1 2 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 15\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 5\n",
      "Draws: 1\n",
      "\n",
      "|[1 0 1 2 1 2 2]|\n",
      "|[2 0 1 2 2 1 2]|\n",
      "|[2 0 1 1 1 2 1]|\n",
      "|[1 2 2 2 1 1 1]|\n",
      "|[1 1 2 1 2 2 1]|\n",
      "|[2 2 1 2 1 2 2]|\n",
      "=================\n",
      "2\n",
      "======\n",
      "Total Plays: 16\n",
      "Depth 6 Wins: 9\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 2 1 0]|\n",
      "|[0 0 0 2 1 2 0]|\n",
      "|[0 0 2 1 2 1 2]|\n",
      "|[1 0 1 1 2 2 2]|\n",
      "|[2 0 1 1 1 2 1]|\n",
      "|[1 1 1 2 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 17\n",
      "Depth 6 Wins: 10\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[2 0 0 0 2 1 1]|\n",
      "|[2 0 0 0 1 2 1]|\n",
      "|[1 0 0 1 1 1 2]|\n",
      "|[2 2 1 1 2 1 2]|\n",
      "|[1 1 2 2 2 1 1]|\n",
      "|[2 1 2 1 2 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 18\n",
      "Depth 6 Wins: 11\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[1 0 2 0 0 0 0]|\n",
      "|[2 2 2 0 2 0 0]|\n",
      "|[2 1 1 1 1 2 1]|\n",
      "|[2 2 1 2 1 1 1]|\n",
      "|[1 1 1 2 1 2 2]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 19\n",
      "Depth 6 Wins: 12\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 2 0 0]|\n",
      "|[0 2 0 2 1 0 0]|\n",
      "|[1 1 1 1 2 0 0]|\n",
      "|[2 2 2 1 2 1 0]|\n",
      "|[2 1 1 1 2 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 20\n",
      "Depth 6 Wins: 13\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[2 0 0 2 2 0 0]|\n",
      "|[1 0 1 1 1 1 2]|\n",
      "|[1 2 2 2 1 1 2]|\n",
      "|[2 1 1 2 2 2 1]|\n",
      "|[1 1 2 2 1 1 2]|\n",
      "|[2 2 1 1 1 2 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 21\n",
      "Depth 6 Wins: 14\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[0 1 1 0 1 0 2]|\n",
      "|[1 1 2 0 2 1 2]|\n",
      "|[2 2 2 0 1 2 2]|\n",
      "|[1 1 1 1 1 2 1]|\n",
      "|[2 1 2 2 1 1 2]|\n",
      "|[2 2 2 1 2 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 22\n",
      "Depth 6 Wins: 15\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[0 0 0 0 2 0 0]|\n",
      "|[0 2 0 0 2 0 0]|\n",
      "|[1 2 0 1 1 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 23\n",
      "Depth 6 Wins: 16\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[0 0 0 0 0 0 0]|\n",
      "|[1 0 0 0 0 0 0]|\n",
      "|[2 0 0 0 0 2 2]|\n",
      "|[2 1 0 0 2 1 1]|\n",
      "|[1 2 1 1 1 1 2]|\n",
      "|[2 2 2 1 2 1 1]|\n",
      "=================\n",
      "1\n",
      "======\n",
      "Total Plays: 24\n",
      "Depth 6 Wins: 17\n",
      "Depth 4 Wins: 6\n",
      "Draws: 1\n",
      "\n",
      "|[1 1 2 1 2 2 2]|\n",
      "|[2 2 1 2 2 1 2]|\n",
      "|[1 1 2 1 1 2 1]|\n",
      "|[1 1 1 2 2 2 1]|\n",
      "|[1 2 2 1 1 1 2]|\n",
      "|[2 2 1 1 2 2 1]|\n",
      "=================\n",
      "0\n",
      "======\n",
      "Total Plays: 25\n",
      "Depth 6 Wins: 17\n",
      "Depth 4 Wins: 6\n",
      "Draws: 2\n"
     ]
    }
   ],
   "source": [
    "default_move = 0\n",
    "\n",
    "def monte_carlo_tree_search(start_state, num_iterations=1000, C=25):\n",
    "    \"\"\"MCTS core loop\"\"\"\n",
    "    root = Tree(start_state=start_state)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        node = traverse(root)\n",
    "        result = rollout(node, start_state)\n",
    "        backpropagate(node, result)\n",
    "\n",
    "    best_child_node = best_child(root)\n",
    "    if best_child_node is not None:\n",
    "        return best_child_node.move\n",
    "    else:\n",
    "        return default_move\n",
    "\n",
    "\n",
    "\n",
    "def best_child(node):\n",
    "    \"\"\"When done sampling, pick the child visited the most.\"\"\"\n",
    "    if not node.children:\n",
    "        return None\n",
    "    return max(node.children, key=lambda x: x.n)\n",
    "\n",
    "def best_uct(node, C=5):\n",
    "    \"\"\"Pick the best action according to the UCB/UCT algorithm\"\"\"\n",
    "    if node.n == 0:\n",
    "        return random.choice(list(node.unexplored_moves))\n",
    "\n",
    "    exploration_term = C * np.sqrt(np.log(node.n) / (node.n + 1))\n",
    "\n",
    "    def uct_value(child):\n",
    "        if child.n == 0:\n",
    "            return float('inf')\n",
    "        return (sum(child.values) / child.n) + exploration_term / np.sqrt(child.n)\n",
    "\n",
    "    if not node.children:\n",
    "        return random.choice(list(node.unexplored_moves))\n",
    "\n",
    "    return max(node.children, key=uct_value).move\n",
    "\n",
    "\n",
    "def traverse(node):\n",
    "    while hasattr(node, 'is_terminal_state') and hasattr(node, 'fully_expanded') and not node.is_terminal_state and not node.fully_expanded:\n",
    "        node = best_uct(node)\n",
    "\n",
    "    if hasattr(node, 'is_terminal_state') and node.is_terminal_state:\n",
    "        return node\n",
    "\n",
    "    if hasattr(node, 'fully_expanded') and node.fully_expanded:\n",
    "        move = best_uct(node).move\n",
    "    elif hasattr(node, 'unexplored_moves'):\n",
    "        move = node.unexplored_moves.pop()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    new_child = Tree(parent=node, move=move)\n",
    "    node.children.add(new_child)\n",
    "    return new_child\n",
    "\n",
    "def rollout(node, start_state):\n",
    "    if node is None or node.state is None:\n",
    "\n",
    "        return 0\n",
    "\n",
    "    winner = node.state.copy().play_random_moves_until_done()\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    elif winner == start_state.current_player:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "\n",
    "def backpropagate(node, simulation_result):\n",
    "    if node is None:\n",
    "        return\n",
    "    node.values.append(simulation_result)\n",
    "    node.n += 1\n",
    "    backpropagate(node.parent, -simulation_result)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation code\n",
    "def print_wins_mcts(wins):\n",
    "    print(\"======\")\n",
    "    print(f\"Total Plays: {len(wins)}\")\n",
    "    print(f\"MCTS Wins: {len([w for w in wins if w == 2])}\")\n",
    "    print(f\"Minimax Wins: {len([w for w in wins if w == 1])}\")\n",
    "    print(f\"Draws: {len([w for w in wins if w == 0])}\")\n",
    "\n",
    "\n",
    "wins = []\n",
    "for _ in range(25):\n",
    "    board = ConnectFourBoard(nrows=6, ncols=7)\n",
    "    board.current_player = random.choice([1, 2])\n",
    "    while board.winner is None:\n",
    "        if board.current_player == 1:\n",
    "            action = minimax(board, depth=5)\n",
    "        else:\n",
    "            action = minimax(board, depth=3)\n",
    "        board.play_move(action)\n",
    "\n",
    "    print(board)\n",
    "    print(board.winner)\n",
    "    wins.append(board.winner)\n",
    "    print_wins_minimax(wins)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CW8h2tD6rB-t",
   "metadata": {
    "id": "CW8h2tD6rB-t"
   },
   "source": [
    "# ANSWER\n",
    "\n",
    "The output of c is 0.5, 5 and 25 is the same\n",
    "\n",
    "## How the behavior of MCTS changes when you change the value of C\n",
    "\n",
    "The MCTS parameter C regulates the ratio of exploration to exploitation. In the search tree, a greater value of C indicates that MCTS will investigate more nodes, whereas a lower value of C indicates that MCTS will utilize the nodes that it has already investigated.\n",
    "\n",
    "Low C increases the likelihood that MCTS will select moves that lead to unknown regions of the search tree. This can be advantageous for developing new and improved tactics, but it can also cause MCTS to act inadvertently in the near term.\n",
    "\n",
    "In situations when C is high, MCTS is more likely to make decisions that lead to areas of the search tree that it has already studied.\n",
    "\n",
    "##Types of ways MCTS wins/loses for different values of C\n",
    "\n",
    "When C is low, MCTS is more likely to succeed in games by developing fresh, superior tactics. Nevertheless, it is also more probable to lose games when you make short-term poor decisions.\n",
    "\n",
    "When C is high, MCTS has a higher chance of winning games by taking advantage of known flaws in the opponent's approach. However, getting locked in local optima also increases the likelihood of losing games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9On-Mn7DuNU6",
   "metadata": {
    "id": "9On-Mn7DuNU6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
